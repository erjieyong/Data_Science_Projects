{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "# import plotData # helper function in starter code package\n",
    "\n",
    "\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "from sktime.classification.compose import ClassifierPipeline, ComposableTimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.summarize import RandomIntervalFeatureExtractor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# only classifier in sktime that can process unequal length data\n",
    "# https://github.com/sktime/sktime/issues/3649#issuecomment-1292459843\n",
    "# from sktime.alignment.dtw_python import AlignerDTW   ## NOTE THAT THIS SOMEHOW AFFECT ALL PRINT OUTPUT. NOTHING WILL BE SHOWN FOR PRINT STATEMENT AFTER YOU RUN THIS\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.classification.dictionary_based import IndividualBOSS, ContractableBOSS\n",
    "\n",
    "from sktime.dists_kernels.compose_from_align import DistFromAligner\n",
    "from sktime.utils.slope_and_trend import _slope\n",
    "from sklearn.pipeline import Pipeline\n",
    "# https://www.sktime.org/en/stable/api_reference/auto_generated/sktime.transformations.panel.catch22.Catch22.html\n",
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "\n",
    "# identify classifiers that support unequal length\n",
    "from sktime.registry import all_estimators\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_test_status = {}\n",
    "for root, dirs, files in os.walk(\"../dataPackage/\"):\n",
    "  for file in files:\n",
    "    try:\n",
    "      if re.search(\"^sub-(cp\\d+)\", file) != None and re.search(\"task-(\\w+)_\", file) != None:\n",
    "        subject = re.search(\"^sub-(cp\\d+)\", file).group(1)\n",
    "        rest_ils = re.search(\"task-(\\w+)_\", file).group(1)\n",
    "        if subject not in resp_test_status:\n",
    "          resp_test_status[subject] = {'ils_lslrespitrace':0, 'rest_lslrespitrace':0, 'ils_lslshimmerresp':0, 'rest_lslshimmerresp':0}\n",
    "        if 'lslrespitrace' in file and 'dat.csv' in file:\n",
    "          resp_test_status[subject][rest_ils+'_lslrespitrace'] += 1\n",
    "        if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "          resp_test_status[subject][rest_ils+'_lslshimmerresp'] += 1\n",
    "    except:\n",
    "      print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(resp_test_status).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lslrespitrace is not used on all subjects. Hence, we will only use lslshimmerresp for respiratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_test_len = {'subject':[],'rest/ils':[],'level':[],'run':[],'len':[],}\n",
    "for root, dirs, files in os.walk(\"..\\\\dataPackage\\\\\"):\n",
    "  for file in files:\n",
    "    try:\n",
    "      if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "        resp_test_len[\"subject\"].append(re.search(\"^sub-(cp\\d+)\", file).group(1))\n",
    "        resp_test_len[\"rest/ils\"].append(re.search(\"task-(\\w+)_\", file).group(1))\n",
    "        resp_test_len[\"level\"].append(re.search(\"level-(\\d\\d\\w)\", file).group(1))\n",
    "        resp_test_len[\"run\"].append(re.search(\"run-(\\d{3})\", file).group(1))\n",
    "        resp_test_len[\"len\"].append(len(pd.read_csv(os.path.join(root, file))))\n",
    "    except:\n",
    "      print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resp_test_len = pd.DataFrame(resp_test_len)\n",
    "df_resp_test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 1000):\n",
    "  display(df_resp_test_len.groupby([\"subject\", \"level\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_addon = {'subject':['cp030', 'cp031'],'rest/ils':['ils', 'ils'],'level':['03B', '01B'],'run':['005', '012'],'len':[0,0]}\n",
    "df_plt = pd.concat([df_resp_test_len, pd.DataFrame(missing_addon)], axis = 0)\n",
    "df_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_compare_datum_len(lvl, df):\n",
    "    df_temp = df[df[\"level\"]==lvl]\n",
    "\n",
    "    x = np.arange(len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]))\n",
    "    y1 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]\n",
    "    y2 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[1]]\n",
    "    y3 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[2]]\n",
    "    width = 0.2\n",
    "\n",
    "    plt.bar(x-0.2, y1, width)\n",
    "    plt.bar(x, y2, width)\n",
    "    plt.bar(x+0.2, y3, width)\n",
    "    plt.xlabel(\"subject\")\n",
    "    plt.ylabel(\"length\")\n",
    "    plt.legend(df_temp[\"run\"].unique())\n",
    "    plt.title(f\"number of datapoints collected from each subject for each run in level {lvl}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_plt[df_plt[\"level\"]==\"03B\"]\n",
    "\n",
    "x = np.arange(len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]].unique()))\n",
    "y1 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]\n",
    "y2 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[1]]\n",
    "y3 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[2]]\n",
    "print(len(y1), len(y2), len(y3), len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lvl in [\"01B\", \"02B\", \"03B\", \"04B\"]:\n",
    "  plt_compare_datum_len(lvl, df_plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_plt[(df_plt[\"level\"]==\"000\")&(df_plt[\"run\"]==\"001\")]\n",
    "x = np.arange(len(df_temp[\"subject\"].unique()))\n",
    "plt.bar(x, df_temp[\"len\"])\n",
    "plt.title(f\"number of datapoints collected from each subject for first run in level 000\")\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that\n",
    "- for CP009, all the first run of each level (including 000 rest), there's only 1 value\n",
    "- for CP030, there's only 2 rounds of level 3B \n",
    "- for CP031, there's 4 rounds of level 2B, but only 2 rounds of level 1B. All others have 3 rounds of each\n",
    "\n",
    "In addition, while length of each run is expected to be different due to different time to land the aircraft, subject 0 (cp003) and subject 6 (cp009) needs to be looked into to see why they are so different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp003\n",
    "cp003_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp003\", \n",
    "                                              \"ses-20210206\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");                                           \n",
    "cp003_run001_dfresp['time_dn'] = pd.to_datetime(cp003_run001_dfresp['time_dn']-719529, unit='D')\n",
    "\n",
    "print(cp003_run001_dfresp.loc[1,\"time_dn\"]- cp003_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp003_run001_dfresp.loc[2,\"time_dn\"]- cp003_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 512 hz\n",
    "print(cp003_run001_dfresp.loc[511,\"time_dn\"]- cp003_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp004\n",
    "cp004_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp004\", \n",
    "                                              \"ses-20210330\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");                                           \n",
    "cp004_run001_dfresp['time_dn'] = pd.to_datetime(cp004_run001_dfresp['time_dn']-719529, unit='D')\n",
    "\n",
    "print(cp004_run001_dfresp.loc[1,\"time_dn\"]- cp004_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp004_run001_dfresp.loc[2,\"time_dn\"]- cp004_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 128 hz\n",
    "print(cp004_run001_dfresp.loc[127,\"time_dn\"]- cp004_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp009\n",
    "cp009_run007_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp009\", \n",
    "                                              \"ses-20210129\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-007\");    # NOTE THAT WE CHANGE TO 2ND RUN                                        \n",
    "cp009_run007_dfresp['time_dn'] = pd.to_datetime(cp009_run007_dfresp['time_dn']-719529, unit='D')\n",
    "cp009_run007_dfresp\n",
    "print(cp009_run007_dfresp.loc[1,\"time_dn\"]- cp009_run007_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp009_run007_dfresp.loc[2,\"time_dn\"]- cp009_run007_dfresp.loc[1,\"time_dn\"])\n",
    "# 512 hz\n",
    "print(cp009_run007_dfresp.loc[511,\"time_dn\"]- cp009_run007_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp009\n",
    "cp011_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp011\", \n",
    "                                              \"ses-20210408\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");    # NOTE THAT WE CHANGE TO 2ND RUN                                        \n",
    "cp011_run001_dfresp['time_dn'] = pd.to_datetime(cp011_run001_dfresp['time_dn']-719529, unit='D')\n",
    "cp011_run001_dfresp\n",
    "print(cp011_run001_dfresp.loc[1,\"time_dn\"]- cp011_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp011_run001_dfresp.loc[2,\"time_dn\"]- cp011_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 128 hz\n",
    "print(cp011_run001_dfresp.loc[127,\"time_dn\"]- cp011_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to sample down the frequency for CP003 and CP009 from 500+ to 128hz to match everyone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore as we will be using the cleaned signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downsample and convert datenum to datetime\n",
    "# for root, dirs, files in os.walk(\"..\\\\dataPackage\\\\\"):\n",
    "#   for file in files:\n",
    "#     try:\n",
    "#       if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "#         if 'cp003' in file or 'cp009' in file:\n",
    "#           df_temp = pd.read_csv(os.path.join(root, file))\n",
    "#           df_temp['time_dn'] = pd.to_datetime(df_temp['time_dn']-719529, unit='D')\n",
    "#           # convert to 128hz\n",
    "#           df_temp = df_temp.resample(str(1/128)+'S', on=\"time_dn\").first().set_index('time_dn')\n",
    "#           df_temp.to_csv(f\"..\\\\myCleanedData\\\\{file}\")\n",
    "#         else:\n",
    "#           #just convert datenum to date and then save to new folder\n",
    "#           df_temp = pd.read_csv(os.path.join(root, file))\n",
    "#           df_temp['time_dn'] = pd.to_datetime(df_temp['time_dn']-719529, unit='D')\n",
    "#           df_temp.to_csv(f\"..\\\\myCleanedData\\\\{file}\", index=False)\n",
    "#     except:\n",
    "#       print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_csv(\"..\\myCleanedData\\sub-cp003_ses-20210206_task-rest_stream-lslshimmerresp_feat-chunk_level-000_run-001_dat.csv\")\n",
    "# x[\"respiration_trace_mV\"][(np.abs(stats.zscore(x[\"respiration_trace_mV\"])) < 3)]\n",
    "# x[\"respiration_trace_mV\"].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean of resting resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean value of all subjects resting resp\n",
    "df_resting_resp_before = {'subject':[], 'mean_rest_resp':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "    if \"lslshimmerresp\" in file and \"000\" in file and \"_1.csv\" in file:\n",
    "      subject = re.search(\"000_(cp\\d+)\", file).group(1)\n",
    "      df_temp = pd.read_csv(os.path.join(root, file))\n",
    "      # remove any outlier that is more than 3sd away from mean\n",
    "      df_temp[\"respiration_trace_mV\"] = df_temp[\"respiration_trace_mV\"][(np.abs(stats.zscore(df_temp[\"respiration_trace_mV\"])) < 3)]\n",
    "  \n",
    "      df_resting_resp_before['subject'].append(subject)\n",
    "      df_resting_resp_before['mean_rest_resp'].append(df_temp[\"respiration_trace_mV\"].mean())\n",
    "pd.DataFrame(df_resting_resp_before)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask aaron, \n",
    "- is there anything wrong in the mean data?\n",
    "- does it make sense to take the difference of activity - rest?\n",
    "\n",
    "Ask XY\n",
    "- cp006 missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise scaled data for cp003\n",
    "scaler = StandardScaler()\n",
    "df_temp = pd.read_csv(\"..\\cleanedData\\lslshimmerresp_respiration_trace_mV_01B_cp003_1.csv\")\n",
    "plt.bar(x =np.arange(len(df_temp['respiration_trace_mV'][::100])), height = scaler.fit_transform(df_temp[['respiration_trace_mV']][::100]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single df\n",
    "df_combined = {'normalised_resp':[], 'difficulty':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"lslshimmerresp\" in file:\n",
    "        difficulty = re.search(\"mV_(\\d\\d\\w)\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        # We perform scaler on EACH subject as they are independent of each other \n",
    "        scaler = StandardScaler()\n",
    "        resp_series = pd.Series(scaler.fit_transform(df_temp[['respiration_trace_mV']]).flatten())\n",
    "\n",
    "        df_combined['normalised_resp'].append(resp_series)\n",
    "        df_combined['difficulty'].append(difficulty)\n",
    "df_combined = pd.DataFrame(df_combined)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle rather than csv to preserve the nested series inside the dataframe\n",
    "df_combined.to_pickle(\"..\\\\cleanedData\\\\df_combined.pkl\", protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data (fitted to rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate scalers for different subject\n",
    "fitted_rest_scaler = {}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"mV_000\" in file and \"_1.csv\" in file:\n",
    "        subject = re.search(\"000_(cp\\d{3})_\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        scaler = StandardScaler()\n",
    "        fitted_rest_scaler[subject] = scaler.fit(df_temp[['respiration_trace_mV']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single df\n",
    "df_combined_fit_rest = {'normalised_resp_rest':[], 'difficulty':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"lslshimmerresp\" in file and \"000\" not in file:\n",
    "        subject = re.search(\"_(cp\\d{3})_\", file).group(1)\n",
    "        difficulty = re.search(\"mV_(\\d\\d\\w)\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        # We perform scaler on EACH subject as they are independent of each other \n",
    "        # BASED ON THEIR RESTING RESP\n",
    "        resp_series = pd.Series(fitted_rest_scaler[subject].transform(df_temp[['respiration_trace_mV']]).flatten())\n",
    "        \n",
    "        df_combined_fit_rest['normalised_resp_rest'].append(resp_series)\n",
    "        df_combined_fit_rest['difficulty'].append(difficulty)\n",
    "df_combined_fit_rest = pd.DataFrame(df_combined_fit_rest)\n",
    "df_combined_fit_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle rather than csv to preserve the nested series inside the dataframe\n",
    "df_combined_fit_rest.to_pickle(\"..\\\\cleanedData\\\\df_combined_fit_rest.pkl\", protocol=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_pickle(\"..\\\\cleanedData\\\\df_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows that is 0 length\n",
    "# empty_row = []\n",
    "# for i in range(len(df_combined)):\n",
    "#   temp = df_combined.iloc[i,0]\n",
    "#   if len(temp[temp==0.0]) or len(temp[temp==0]):\n",
    "#     empty_row.append(i)\n",
    "\n",
    "# df_combined.drop(empty_row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_combined[\"normalised_resp\"], df_combined[\"difficulty\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = y_train.astype(\"string\")\n",
    "y_test = y_test.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_fit_rest = pd.read_pickle(\"..\\\\cleanedData\\\\df_combined_fit_rest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows that is 0 length\n",
    "empty_row = []\n",
    "for i in range(len(df_combined_fit_rest)):\n",
    "  temp = df_combined_fit_rest.iloc[i,0]\n",
    "  if len(temp[temp==0.0]) or len(temp[temp==0]):\n",
    "    empty_row.append(i)\n",
    "\n",
    "df_combined_fit_rest.drop(empty_row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_rest_train, X_fit_rest_test, y_fit_rest_train, y_fit_rest_test = train_test_split(df_combined_fit_rest[\"normalised_resp_rest\"], df_combined_fit_rest[\"difficulty\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_rest_train = pd.DataFrame(X_fit_rest_train)\n",
    "X_fit_rest_test = pd.DataFrame(X_fit_rest_test)\n",
    "y_fit_rest_train = y_fit_rest_train.astype(\"string\")\n",
    "y_fit_rest_test = y_fit_rest_test.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = {\n",
    "  \"classifier\":[],\n",
    "  \"accuracy_score\":[],\n",
    "  \"AUC_score\":[],\n",
    "  \"F1_score\":[]\n",
    "}\n",
    "\n",
    "def get_class(class_list, prob_list):\n",
    "  idx = list(prob_list).index(max(prob_list))\n",
    "  return class_list[idx]\n",
    "\n",
    "def log_result(classifier, class_list, y_test, y_pred_proba):\n",
    "  y_pred = []\n",
    "  for y_list in y_pred_proba:\n",
    "    y_pred.append(get_class(class_list, y_list))\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "  f1 = f1_score(y_test, y_pred, average='micro')\n",
    "  model_result[\"classifier\"].append(classifier)\n",
    "  model_result[\"accuracy_score\"].append(acc)\n",
    "  model_result[\"AUC_score\"].append(auc)\n",
    "  model_result[\"F1_score\"].append(f1)\n",
    "\n",
    "  display(pd.DataFrame(model_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# search for all classifiers which can handle unequal length data. This may give some\n",
    "# UserWarnings if soft dependencies are not installed.\n",
    "all_estimators(\n",
    "    filter_tags={\"capability:unequal_length\": True}, estimator_types=\"classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligner = AlignerDTW()\n",
    "# dtw_dist = DistFromAligner(aligner)\n",
    "# knclassifier = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance = dtw_dist, n_jobs= -1)\n",
    "# knclassifier.fit(X_train, y_train)\n",
    "# y_pred = knclassifier.predict(X_test)\n",
    "\n",
    "# log_result('KNeighborsTimeSeriesClassifier',y_test, y_pred)\n",
    "\n",
    "# NO MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_KN_pipeline = ClassifierPipeline(\n",
    "#     KNeighborsTimeSeriesClassifier(n_neighbors=5, distance =\"dtw\", n_jobs= 1, leaf_size = 2000), \n",
    "#     [PaddingTransformer()]\n",
    "# )\n",
    "# padded_KN_pipeline.fit(X_train, y_train)\n",
    "# y_pred = padded_KN_pipeline.predict(X_test)\n",
    "\n",
    "# log_result('KNeighborsTimeSeriesClassifier',y_test, y_pred)\n",
    "\n",
    "# NO MEMORY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomIntervalClassifier\n",
    "extract at random interval and perform Rotation forest with 200 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherwise, we have to use paddingtransformer to process the unequal length\n",
    "padded_clf = PaddingTransformer() * RandomIntervalClassifier(n_intervals=5, n_jobs=-1, random_state = 42)\n",
    "padded_clf.fit(X_train, y_train)\n",
    "y_pred_proba = padded_clf.predict_proba(X_test)\n",
    "\n",
    "log_result('RandomIntervalClassifier',padded_clf.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherwise, we have to use paddingtransformer to process the unequal length\n",
    "padded_clf = PaddingTransformer() * RandomIntervalClassifier(n_intervals=5, n_jobs=-1, random_state = 42)\n",
    "padded_clf.fit(X_fit_rest_train, y_fit_rest_train)\n",
    "y_fit_rest_pred_proba = padded_clf.predict_proba(X_fit_rest_test)\n",
    "\n",
    "log_result('RandomIntervalClassifier_fit_rest',padded_clf.classes_, y_fit_rest_test, y_fit_rest_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees with mean, std, slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"padding\",PaddingTransformer()),\n",
    "    (\n",
    "        \"extract\",\n",
    "        RandomIntervalFeatureExtractor(\n",
    "            n_intervals=\"sqrt\", features=[np.mean, np.std, _slope]\n",
    "        ),\n",
    "    ),\n",
    "    (\"clf\", DecisionTreeClassifier()),\n",
    "]\n",
    "time_series_tree = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_tree.fit(X_train, y_train)\n",
    "time_series_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = time_series_tree.predict_proba(X_test)\n",
    "log_result('time_series_tree',time_series_tree.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_tree.fit(X_fit_rest_train, y_fit_rest_train)\n",
    "y_fit_rest_pred_proba = time_series_tree.predict_proba(X_fit_rest_test)\n",
    "log_result('time_series_tree_rest_fit',time_series_tree.classes_, y_fit_rest_test, y_fit_rest_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComposableTimeSeriesForestClassifier\n",
    "https://www.sktime.org/en/v0.8.1/examples/02_classification_univariate.html\n",
    "\n",
    "## ON PAUSE CAUSE TAKES TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sktime.org/en/v0.8.1/examples/02_classification_univariate.html\n",
    "tsf_tst = PaddingTransformer() * ComposableTimeSeriesForestClassifier(\n",
    "    estimator=time_series_tree,\n",
    "    n_estimators=100,\n",
    "    # criterion=\"entropy\",\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "tsf_tst.fit(X_train, y_train.astype(\"string\"))\n",
    "\n",
    "if tsf_tst.oob_score:\n",
    "    print(tsf.oob_score_)\n",
    "\n",
    "y_pred_proba = tsf_tst.predict_proba(X_test)\n",
    "\n",
    "log_result('tsf_time_series_forest',tsf_tst.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = ComposableTimeSeriesForestClassifier()\n",
    "tsf.fit(X_train, y_train)\n",
    "y_pred_proba = tsf.predict_proba(X_test)\n",
    "log_result('TimeSeriesForestClassifier',tsf.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22 = PaddingTransformer() * Catch22()\n",
    "X_train_catch22 = catch22.fit_transform(X_train)\n",
    "X_test_catch22 = catch22.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_catch22.to_csv(\"..\\\\cleanedData\\\\X_train_catch22.csv\")\n",
    "X_test_catch22.to_csv(\"..\\\\cleanedData\\\\X_test_catch22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Boss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iboss = PaddingTransformer() * IndividualBOSS()\n",
    "iboss.fit(X_train, y_train)\n",
    "y_pred_proba = iboss.predict_proba(X_test)\n",
    "\n",
    "log_result('RandomIntervalClassifier',iboss.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "# import plotData # helper function in starter code package\n",
    "\n",
    "\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "from sktime.classification.compose import ClassifierPipeline, ComposableTimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.summarize import RandomIntervalFeatureExtractor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# only classifier in sktime that can process unequal length data\n",
    "# https://github.com/sktime/sktime/issues/3649#issuecomment-1292459843\n",
    "# from sktime.alignment.dtw_python import AlignerDTW   ## NOTE THAT THIS SOMEHOW AFFECT ALL PRINT OUTPUT. NOTHING WILL BE SHOWN FOR PRINT STATEMENT AFTER YOU RUN THIS\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.classification.dictionary_based import IndividualBOSS, ContractableBOSS\n",
    "\n",
    "from sktime.dists_kernels.compose_from_align import DistFromAligner\n",
    "from sktime.utils.slope_and_trend import _slope\n",
    "from sklearn.pipeline import Pipeline\n",
    "# https://www.sktime.org/en/stable/api_reference/auto_generated/sktime.transformations.panel.catch22.Catch22.html\n",
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "\n",
    "# identify classifiers that support unequal length\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "df_combined = pd.read_pickle(\"..\\\\cleanedData\\\\df_combined.pkl\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_combined[\"normalised_resp\"], df_combined[\"difficulty\"], random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = y_train.astype(\"string\")\n",
    "y_test = y_test.astype(\"string\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "None\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\appdata\\local\\temp\\ipykernel_13228\\2151808917.py\u001b[0m(4)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\n",
      "\u001b[1;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\anaconda3\\envs\\cogpilot\\lib\\site-packages\\ipython\\core\\interactiveshell.py\u001b[0m(3436)\u001b[0;36mrun_code\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   3434 \u001b[1;33m            \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3435 \u001b[1;33m                \u001b[1;31m# Reset our crash handler in place\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 3436 \u001b[1;33m                \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexcepthook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mold_excepthook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3437 \u001b[1;33m        \u001b[1;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3438 \u001b[1;33m            \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\anaconda3\\envs\\cogpilot\\lib\\site-packages\\ipython\\core\\interactiveshell.py\u001b[0m(3457)\u001b[0;36mrun_code\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   3455 \u001b[1;33m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3456 \u001b[1;33m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 3457 \u001b[1;33m            \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3458 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0moutflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3459 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\anaconda3\\envs\\cogpilot\\lib\\site-packages\\ipython\\core\\interactiveshell.py\u001b[0m(3458)\u001b[0;36mrun_code\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   3456 \u001b[1;33m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3457 \u001b[1;33m            \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 3458 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0moutflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3459 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3460 \u001b[1;33m    \u001b[1;31m# For backwards compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;31m    [... skipped 1 hidden frame]\u001b[0m\n",
      "\n",
      "Internal StopIteration: False\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\anaconda3\\envs\\cogpilot\\lib\\site-packages\\ipython\\core\\interactiveshell.py\u001b[0m(3373)\u001b[0;36mrun_ast_nodes\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   3371 \u001b[1;33m                    \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3372 \u001b[1;33m                    \u001b[0masy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 3373 \u001b[1;33m                \u001b[1;32mif\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3374 \u001b[1;33m                    \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3375 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "> \u001b[1;32mc:\\users\\kyunomi\\anaconda3\\envs\\cogpilot\\lib\\site-packages\\ipython\\core\\interactiveshell.py\u001b[0m(3361)\u001b[0;36mrun_ast_nodes\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m   3359 \u001b[1;33m                \u001b[0mto_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"single\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3360 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m-> 3361 \u001b[1;33m            \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3362 \u001b[1;33m                \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"exec\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m   3363 \u001b[1;33m                    \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "*** NameError: name 'pdb' is not defined\n",
      "\n",
      "Documented commands (type help <topic>):\n",
      "========================================\n",
      "EOF    commands   enable    ll        pp       s                until \n",
      "a      condition  exit      longlist  psource  skip_hidden      up    \n",
      "alias  cont       h         n         q        skip_predicates  w     \n",
      "args   context    help      next      quit     source           whatis\n",
      "b      continue   ignore    p         r        step             where \n",
      "break  d          interact  pdef      restart  tbreak         \n",
      "bt     debug      j         pdoc      return   u              \n",
      "c      disable    jump      pfile     retval   unalias        \n",
      "cl     display    l         pinfo     run      undisplay      \n",
      "clear  down       list      pinfo2    rv       unt            \n",
      "\n",
      "Miscellaneous help topics:\n",
      "==========================\n",
      "exec  pdb\n",
      "\n",
      "\u001b[0;32m   3356 \u001b[0m                \u001b[0mto_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3357 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3358 \u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_run_interactive\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3359 \u001b[0m                \u001b[0mto_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"single\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3360 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 3361 \u001b[1;33m            \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_run\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   3362 \u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"exec\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3363 \u001b[0m                    \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3364 \u001b[0m                \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"single\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3365 \u001b[0m                    \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3366 \u001b[0m                with compiler.extra_flags(\n",
      "\n",
      "\u001b[0;32m   3367 \u001b[0m                    \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PyCF_ALLOW_TOP_LEVEL_AWAIT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0x0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3368 \u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoawait\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3369 \u001b[0m                    \u001b[1;32melse\u001b[0m \u001b[1;36m0x0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3370 \u001b[0m                ):\n",
      "\u001b[0;32m   3371 \u001b[0m                    \u001b[0mcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3372 \u001b[0m                    \u001b[0masy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3373 \u001b[0m                \u001b[1;32mif\u001b[0m \u001b[1;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0masy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3374 \u001b[0m                    \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3375 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3376 \u001b[0m            \u001b[1;31m# Flush softspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3377 \u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0msoftspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m   3378 \u001b[0m                \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3379 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3380 \u001b[0m        \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3381 \u001b[0m            \u001b[1;31m# It's possible to have exceptions raised here, typically by\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3382 \u001b[0m            \u001b[1;31m# compilation of odd code (such as a naked 'return' outside a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3383 \u001b[0m            \u001b[1;31m# function) that did parse but isn't valid. Typically the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3384 \u001b[0m            \u001b[1;31m# is a SyntaxError, but it's safest just to catch anything and show\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3385 \u001b[0m            \u001b[1;31m# the user a traceback.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3386 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3387 \u001b[0m            \u001b[1;31m# We do only one try/except outside the loop to minimize the impact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3388 \u001b[0m            \u001b[1;31m# on runtime, and also because if any node in the node list is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m   3389 \u001b[0m            \u001b[1;31m# broken, we should stop execution completely.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3390 \u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3391 \u001b[0m                \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3392 \u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3393 \u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3394 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3395 \u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3396 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3397 \u001b[0m    \u001b[1;32masync\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masync_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   3398 \u001b[0m        \"\"\"Execute a code object.\n",
      "\u001b[0;32m   3399 \u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "iboss = PaddingTransformer() * IndividualBOSS()\n",
    "iboss.fit(X_train[0:3], y_train[0:3])\n",
    "set_trace()\n",
    "\n",
    "y_pred = iboss.predict(X_train[0:1])\n",
    "\n",
    "# y_pred_proba = iboss.predict_proba(X_test[[\"normalised_resp\"]][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0'], dtype='<U1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pdb' from 'c:\\\\Users\\\\kyunomi\\\\anaconda3\\\\envs\\\\cogpilot\\\\lib\\\\pdb.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whatis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.dictionary_based import IndividualBOSS\n",
    "from sktime.datasets import load_unit_test\n",
    "X_train, y_train = load_unit_test(split=\"train\", return_X_y=True)\n",
    "X_test, y_test = load_unit_test(split=\"test\", return_X_y=True)\n",
    "clf = IndividualBOSS()\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try looking\n",
    "- filter out different subject with different resp hz then do training for them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogpilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a6363372e1d778c4137ad4a53928cfc69136b01ab6f02bce312c553d9eae285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
