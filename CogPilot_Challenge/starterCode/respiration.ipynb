{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from matplotlib import pyplot as plt\n",
    "# import plotData # helper function in starter code package\n",
    "\n",
    "\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "from sktime.classification.compose import ClassifierPipeline, ComposableTimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.summarize import RandomIntervalFeatureExtractor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# only classifier in sktime that can process unequal length data\n",
    "# https://github.com/sktime/sktime/issues/3649#issuecomment-1292459843\n",
    "# from sktime.alignment.dtw_python import AlignerDTW   ## NOTE THAT THIS SOMEHOW AFFECT ALL PRINT OUTPUT. NOTHING WILL BE SHOWN FOR PRINT STATEMENT AFTER YOU RUN THIS\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.classification.dictionary_based import IndividualBOSS, ContractableBOSS\n",
    "from sktime.classification.kernel_based import RocketClassifier\n",
    "from sktime.classification.hybrid import HIVECOTEV1, HIVECOTEV2\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "\n",
    "from sktime.dists_kernels.compose_from_align import DistFromAligner\n",
    "from sktime.utils.slope_and_trend import _slope\n",
    "from sklearn.pipeline import Pipeline\n",
    "# https://www.sktime.org/en/stable/api_reference/auto_generated/sktime.transformations.panel.catch22.Catch22.html\n",
    "from sktime.transformations.panel.catch22 import Catch22\n",
    "\n",
    "from sktime.classification.interval_based import CanonicalIntervalForest,DrCIF,RandomIntervalSpectralEnsemble,SupervisedTimeSeriesForest,TimeSeriesForestClassifier\n",
    "\n",
    "# identify classifiers that support unequal length\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_test_status = {}\n",
    "for root, dirs, files in os.walk(\"../dataPackage/\"):\n",
    "  for file in files:\n",
    "    try:\n",
    "      if re.search(\"^sub-(cp\\d+)\", file) != None and re.search(\"task-(\\w+)_\", file) != None:\n",
    "        subject = re.search(\"^sub-(cp\\d+)\", file).group(1)\n",
    "        rest_ils = re.search(\"task-(\\w+)_\", file).group(1)\n",
    "        if subject not in resp_test_status:\n",
    "          resp_test_status[subject] = {'ils_lslrespitrace':0, 'rest_lslrespitrace':0, 'ils_lslshimmerresp':0, 'rest_lslshimmerresp':0}\n",
    "        if 'lslrespitrace' in file and 'dat.csv' in file:\n",
    "          resp_test_status[subject][rest_ils+'_lslrespitrace'] += 1\n",
    "        if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "          resp_test_status[subject][rest_ils+'_lslshimmerresp'] += 1\n",
    "    except:\n",
    "      print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ils_lslrespitrace</th>\n",
       "      <th>rest_lslrespitrace</th>\n",
       "      <th>ils_lslshimmerresp</th>\n",
       "      <th>rest_lslshimmerresp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cp003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp008</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp009</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp011</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp012</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp013</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp014</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp015</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp016</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp018</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp020</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp022</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp023</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp024</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp025</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp026</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp028</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp029</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp030</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp031</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp032</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp033</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp035</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp036</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp037</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp038</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp039</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp042</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp043</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ils_lslrespitrace  rest_lslrespitrace  ils_lslshimmerresp  \\\n",
       "cp003                  0                   0                  12   \n",
       "cp004                  0                   0                  12   \n",
       "cp005                  0                   0                  12   \n",
       "cp006                  0                   0                  12   \n",
       "cp008                  0                   0                  12   \n",
       "cp009                  0                   0                  12   \n",
       "cp011                  0                   0                  12   \n",
       "cp012                  0                   0                  12   \n",
       "cp013                  0                   0                  12   \n",
       "cp014                 12                   2                  12   \n",
       "cp015                  0                   0                  12   \n",
       "cp016                  0                   0                  12   \n",
       "cp017                  0                   0                  12   \n",
       "cp018                  0                   0                  12   \n",
       "cp019                  0                   0                  12   \n",
       "cp020                  0                   0                  12   \n",
       "cp022                  0                   0                  12   \n",
       "cp023                  0                   0                  12   \n",
       "cp024                  0                   0                  12   \n",
       "cp025                 12                   2                  12   \n",
       "cp026                  0                   0                  12   \n",
       "cp027                  0                   0                  12   \n",
       "cp028                 12                   2                  12   \n",
       "cp029                 12                   2                  12   \n",
       "cp030                 10                   1                  11   \n",
       "cp031                 12                   2                  12   \n",
       "cp032                 12                   2                  12   \n",
       "cp033                 12                   2                  12   \n",
       "cp035                 12                   2                  12   \n",
       "cp036                 12                   1                  12   \n",
       "cp037                 12                   2                  12   \n",
       "cp038                 12                   2                  12   \n",
       "cp039                 12                   2                  12   \n",
       "cp042                 12                   2                  12   \n",
       "cp043                 12                   2                  12   \n",
       "\n",
       "       rest_lslshimmerresp  \n",
       "cp003                    2  \n",
       "cp004                    2  \n",
       "cp005                    2  \n",
       "cp006                    2  \n",
       "cp008                    2  \n",
       "cp009                    1  \n",
       "cp011                    2  \n",
       "cp012                    2  \n",
       "cp013                    2  \n",
       "cp014                    2  \n",
       "cp015                    2  \n",
       "cp016                    2  \n",
       "cp017                    2  \n",
       "cp018                    2  \n",
       "cp019                    2  \n",
       "cp020                    2  \n",
       "cp022                    2  \n",
       "cp023                    2  \n",
       "cp024                    2  \n",
       "cp025                    2  \n",
       "cp026                    2  \n",
       "cp027                    2  \n",
       "cp028                    2  \n",
       "cp029                    2  \n",
       "cp030                    2  \n",
       "cp031                    2  \n",
       "cp032                    2  \n",
       "cp033                    2  \n",
       "cp035                    2  \n",
       "cp036                    1  \n",
       "cp037                    2  \n",
       "cp038                    2  \n",
       "cp039                    2  \n",
       "cp042                    2  \n",
       "cp043                    2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(resp_test_status).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lslrespitrace is not used on all subjects. Hence, we will only use lslshimmerresp for respiratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-cp004_ses-20210330_task-ils_stream-lslshimmerresp_feat-chunk_level-01B_run-007_dat.csv\n"
     ]
    }
   ],
   "source": [
    "resp_test_len = {'subject':[],'rest/ils':[],'level':[],'run':[],'len':[],}\n",
    "for root, dirs, files in os.walk(\"..\\\\dataPackage\\\\\"):\n",
    "  for file in files:\n",
    "    try:\n",
    "      if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "        resp_test_len[\"subject\"].append(re.search(\"^sub-(cp\\d+)\", file).group(1))\n",
    "        resp_test_len[\"rest/ils\"].append(re.search(\"task-(\\w+)_\", file).group(1))\n",
    "        resp_test_len[\"level\"].append(re.search(\"level-(\\d\\d\\w)\", file).group(1))\n",
    "        resp_test_len[\"run\"].append(re.search(\"run-(\\d{3})\", file).group(1))\n",
    "        resp_test_len[\"len\"].append(len(pd.read_csv(os.path.join(root, file))))\n",
    "    except:\n",
    "      print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resp_test_len = pd.DataFrame(resp_test_len)\n",
    "df_resp_test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", 1000):\n",
    "  display(df_resp_test_len.groupby([\"subject\", \"level\"]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_addon = {'subject':['cp030', 'cp031'],'rest/ils':['ils', 'ils'],'level':['03B', '01B'],'run':['005', '012'],'len':[0,0]}\n",
    "df_plt = pd.concat([df_resp_test_len, pd.DataFrame(missing_addon)], axis = 0)\n",
    "df_plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_compare_datum_len(lvl, df):\n",
    "    df_temp = df[df[\"level\"]==lvl]\n",
    "\n",
    "    x = np.arange(len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]))\n",
    "    y1 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]\n",
    "    y2 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[1]]\n",
    "    y3 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[2]]\n",
    "    width = 0.2\n",
    "\n",
    "    plt.bar(x-0.2, y1, width)\n",
    "    plt.bar(x, y2, width)\n",
    "    plt.bar(x+0.2, y3, width)\n",
    "    plt.xlabel(\"subject\")\n",
    "    plt.ylabel(\"length\")\n",
    "    plt.legend(df_temp[\"run\"].unique())\n",
    "    plt.title(f\"number of datapoints collected from each subject for each run in level {lvl}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_plt[df_plt[\"level\"]==\"03B\"]\n",
    "\n",
    "x = np.arange(len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]].unique()))\n",
    "y1 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]]\n",
    "y2 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[1]]\n",
    "y3 = df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[2]]\n",
    "print(len(y1), len(y2), len(y3), len(df_temp[\"len\"][df_temp[\"run\"]==df_temp[\"run\"].unique()[0]].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lvl in [\"01B\", \"02B\", \"03B\", \"04B\"]:\n",
    "  plt_compare_datum_len(lvl, df_plt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_plt[(df_plt[\"level\"]==\"000\")&(df_plt[\"run\"]==\"001\")]\n",
    "x = np.arange(len(df_temp[\"subject\"].unique()))\n",
    "plt.bar(x, df_temp[\"len\"])\n",
    "plt.title(f\"number of datapoints collected from each subject for first run in level 000\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that\n",
    "- for CP009, all the first run of each level (including 000 rest), there's only 1 value\n",
    "- for CP030, there's only 2 rounds of level 3B \n",
    "- for CP031, there's 4 rounds of level 2B, but only 2 rounds of level 1B. All others have 3 rounds of each\n",
    "\n",
    "In addition, while length of each run is expected to be different due to different time to land the aircraft, subject 0 (cp003) and subject 6 (cp009) needs to be looked into to see why they are so different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp003\n",
    "cp003_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp003\", \n",
    "                                              \"ses-20210206\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");                                           \n",
    "cp003_run001_dfresp['time_dn'] = pd.to_datetime(cp003_run001_dfresp['time_dn']-719529, unit='D')\n",
    "\n",
    "print(cp003_run001_dfresp.loc[1,\"time_dn\"]- cp003_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp003_run001_dfresp.loc[2,\"time_dn\"]- cp003_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 512 hz\n",
    "print(cp003_run001_dfresp.loc[511,\"time_dn\"]- cp003_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp004\n",
    "cp004_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp004\", \n",
    "                                              \"ses-20210330\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");                                           \n",
    "cp004_run001_dfresp['time_dn'] = pd.to_datetime(cp004_run001_dfresp['time_dn']-719529, unit='D')\n",
    "\n",
    "print(cp004_run001_dfresp.loc[1,\"time_dn\"]- cp004_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp004_run001_dfresp.loc[2,\"time_dn\"]- cp004_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 128 hz\n",
    "print(cp004_run001_dfresp.loc[127,\"time_dn\"]- cp004_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp009\n",
    "cp009_run007_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp009\", \n",
    "                                              \"ses-20210129\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-007\");    # NOTE THAT WE CHANGE TO 2ND RUN                                        \n",
    "cp009_run007_dfresp['time_dn'] = pd.to_datetime(cp009_run007_dfresp['time_dn']-719529, unit='D')\n",
    "cp009_run007_dfresp\n",
    "print(cp009_run007_dfresp.loc[1,\"time_dn\"]- cp009_run007_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp009_run007_dfresp.loc[2,\"time_dn\"]- cp009_run007_dfresp.loc[1,\"time_dn\"])\n",
    "# 512 hz\n",
    "print(cp009_run007_dfresp.loc[511,\"time_dn\"]- cp009_run007_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp009\n",
    "cp011_run001_dfresp = plotData.loadTimeSeries(\"..\\dataPackage\", \n",
    "                                              \"sub-cp011\", \n",
    "                                              \"ses-20210408\", \n",
    "                                              \"task-ils\", \n",
    "                                              \"lslshimmerresp\", \n",
    "                                              \"level-01B_run-001\");    # NOTE THAT WE CHANGE TO 2ND RUN                                        \n",
    "cp011_run001_dfresp['time_dn'] = pd.to_datetime(cp011_run001_dfresp['time_dn']-719529, unit='D')\n",
    "cp011_run001_dfresp\n",
    "print(cp011_run001_dfresp.loc[1,\"time_dn\"]- cp011_run001_dfresp.loc[0,\"time_dn\"])\n",
    "print(cp011_run001_dfresp.loc[2,\"time_dn\"]- cp011_run001_dfresp.loc[1,\"time_dn\"])\n",
    "# 128 hz\n",
    "print(cp011_run001_dfresp.loc[127,\"time_dn\"]- cp011_run001_dfresp.loc[0,\"time_dn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to sample down the frequency for CP003 and CP009 from 500+ to 128hz to match everyone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore as we will be using the cleaned signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downsample and convert datenum to datetime\n",
    "# for root, dirs, files in os.walk(\"..\\\\dataPackage\\\\\"):\n",
    "#   for file in files:\n",
    "#     try:\n",
    "#       if 'lslshimmerresp' in file and 'dat.csv' in file:\n",
    "#         if 'cp003' in file or 'cp009' in file:\n",
    "#           df_temp = pd.read_csv(os.path.join(root, file))\n",
    "#           df_temp['time_dn'] = pd.to_datetime(df_temp['time_dn']-719529, unit='D')\n",
    "#           # convert to 128hz\n",
    "#           df_temp = df_temp.resample(str(1/128)+'S', on=\"time_dn\").first().set_index('time_dn')\n",
    "#           df_temp.to_csv(f\"..\\\\myCleanedData\\\\{file}\")\n",
    "#         else:\n",
    "#           #just convert datenum to date and then save to new folder\n",
    "#           df_temp = pd.read_csv(os.path.join(root, file))\n",
    "#           df_temp['time_dn'] = pd.to_datetime(df_temp['time_dn']-719529, unit='D')\n",
    "#           df_temp.to_csv(f\"..\\\\myCleanedData\\\\{file}\", index=False)\n",
    "#     except:\n",
    "#       print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd.read_csv(\"..\\myCleanedData\\sub-cp003_ses-20210206_task-rest_stream-lslshimmerresp_feat-chunk_level-000_run-001_dat.csv\")\n",
    "# x[\"respiration_trace_mV\"][(np.abs(stats.zscore(x[\"respiration_trace_mV\"])) < 3)]\n",
    "# x[\"respiration_trace_mV\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get mean of resting resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean value of all subjects resting resp\n",
    "df_resting_resp_before = {'subject':[], 'mean_rest_resp':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "    if \"lslshimmerresp\" in file and \"000\" in file and \"_1.csv\" in file:\n",
    "      subject = re.search(\"000_(cp\\d+)\", file).group(1)\n",
    "      df_temp = pd.read_csv(os.path.join(root, file))\n",
    "      # remove any outlier that is more than 3sd away from mean\n",
    "      df_temp[\"respiration_trace_mV\"] = df_temp[\"respiration_trace_mV\"][(np.abs(stats.zscore(df_temp[\"respiration_trace_mV\"])) < 3)]\n",
    "  \n",
    "      df_resting_resp_before['subject'].append(subject)\n",
    "      df_resting_resp_before['mean_rest_resp'].append(df_temp[\"respiration_trace_mV\"].mean())\n",
    "pd.DataFrame(df_resting_resp_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ask aaron, \n",
    "- is there anything wrong in the mean data?\n",
    "- does it make sense to take the difference of activity - rest?\n",
    "\n",
    "Ask XY\n",
    "- cp006 missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise scaled data for cp003\n",
    "scaler = StandardScaler()\n",
    "df_temp = pd.read_csv(\"..\\cleanedData\\lslshimmerresp_respiration_trace_mV_01B_cp003_1.csv\")\n",
    "plt.bar(x =np.arange(len(df_temp['respiration_trace_mV'][::100])), height = scaler.fit_transform(df_temp[['respiration_trace_mV']][::100]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single df\n",
    "df_combined = {'normalised_resp':[], 'difficulty':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"lslshimmerresp\" in file:\n",
    "        difficulty = re.search(\"mV_(\\d\\d\\w)\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        # We perform scaler on EACH subject as they are independent of each other \n",
    "        scaler = StandardScaler()\n",
    "        resp_series = pd.Series(scaler.fit_transform(df_temp[['respiration_trace_mV']]).flatten())\n",
    "\n",
    "        df_combined['normalised_resp'].append(resp_series)\n",
    "        df_combined['difficulty'].append(difficulty)\n",
    "df_combined = pd.DataFrame(df_combined)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle rather than csv to preserve the nested series inside the dataframe\n",
    "df_combined.to_pickle(\"..\\\\cleanedData\\\\df_combined.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data (fitted to rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate scalers for different subject\n",
    "fitted_rest_scaler = {}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"mV_000\" in file and \"_1.csv\" in file:\n",
    "        subject = re.search(\"000_(cp\\d{3})_\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        scaler = StandardScaler()\n",
    "        fitted_rest_scaler[subject] = scaler.fit(df_temp[['respiration_trace_mV']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into single df\n",
    "df_combined_fit_rest = {'normalised_resp_rest':[], 'difficulty':[]}\n",
    "for root, dirs, files in os.walk(\"..\\\\cleanedData\\\\\"):\n",
    "  for file in files:\n",
    "      if \"lslshimmerresp\" in file and \"000\" not in file:\n",
    "        subject = re.search(\"_(cp\\d{3})_\", file).group(1)\n",
    "        difficulty = re.search(\"mV_(\\d\\d\\w)\", file).group(1)\n",
    "        df_temp = pd.read_csv(os.path.join(root, file))\n",
    "        # We perform scaler on EACH subject as they are independent of each other \n",
    "        # BASED ON THEIR RESTING RESP\n",
    "        resp_series = pd.Series(fitted_rest_scaler[subject].transform(df_temp[['respiration_trace_mV']]).flatten())\n",
    "        \n",
    "        df_combined_fit_rest['normalised_resp_rest'].append(resp_series)\n",
    "        df_combined_fit_rest['difficulty'].append(difficulty)\n",
    "df_combined_fit_rest = pd.DataFrame(df_combined_fit_rest)\n",
    "df_combined_fit_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle rather than csv to preserve the nested series inside the dataframe\n",
    "df_combined_fit_rest.to_pickle(\"..\\\\cleanedData\\\\df_combined_fit_rest.pkl\", protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_pickle(\"..\\\\cleanedData\\\\df_combined.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows that is 0 length\n",
    "# empty_row = []\n",
    "# for i in range(len(df_combined)):\n",
    "#   temp = df_combined.iloc[i,0]\n",
    "#   if len(temp[temp==0.0]) or len(temp[temp==0]):\n",
    "#     empty_row.append(i)\n",
    "\n",
    "# df_combined.drop(empty_row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_combined[\"normalised_resp\"], df_combined[\"difficulty\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "y_train = y_train.astype(\"string\")\n",
    "y_test = y_test.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_fit_rest = pd.read_pickle(\"..\\\\cleanedData\\\\df_combined_fit_rest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows that is 0 length\n",
    "empty_row = []\n",
    "for i in range(len(df_combined_fit_rest)):\n",
    "  temp = df_combined_fit_rest.iloc[i,0]\n",
    "  if len(temp[temp==0.0]) or len(temp[temp==0]):\n",
    "    empty_row.append(i)\n",
    "\n",
    "df_combined_fit_rest.drop(empty_row, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_rest_train, X_fit_rest_test, y_fit_rest_train, y_fit_rest_test = train_test_split(df_combined_fit_rest[\"normalised_resp_rest\"], df_combined_fit_rest[\"difficulty\"], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit_rest_train = pd.DataFrame(X_fit_rest_train)\n",
    "X_fit_rest_test = pd.DataFrame(X_fit_rest_test)\n",
    "y_fit_rest_train = y_fit_rest_train.astype(\"string\")\n",
    "y_fit_rest_test = y_fit_rest_test.astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = {\n",
    "  \"classifier\":[],\n",
    "  \"accuracy_score\":[],\n",
    "  \"AUC_score\":[],\n",
    "  \"F1_score\":[]\n",
    "}\n",
    "\n",
    "def get_class(class_list, prob_list):\n",
    "  idx = list(prob_list).index(max(prob_list))\n",
    "  return class_list[idx]\n",
    "\n",
    "def log_result(classifier, class_list, y_test, y_pred_proba):\n",
    "  y_pred = []\n",
    "  for y_list in y_pred_proba:\n",
    "    y_pred.append(get_class(class_list, y_list))\n",
    "  acc = accuracy_score(y_test, y_pred)\n",
    "  auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
    "  f1 = f1_score(y_test, y_pred, average='micro')\n",
    "  model_result[\"classifier\"].append(classifier)\n",
    "  model_result[\"accuracy_score\"].append(acc)\n",
    "  model_result[\"AUC_score\"].append(auc)\n",
    "  model_result[\"F1_score\"].append(f1)\n",
    "\n",
    "  display(pd.DataFrame(model_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# search for all classifiers which can handle unequal length data. This may give some\n",
    "# UserWarnings if soft dependencies are not installed.\n",
    "all_estimators(\n",
    "    filter_tags={\"capability:unequal_length\": True}, estimator_types=\"classifier\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligner = AlignerDTW()\n",
    "# dtw_dist = DistFromAligner(aligner)\n",
    "# knclassifier = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance = dtw_dist, n_jobs= -1)\n",
    "# knclassifier.fit(X_train, y_train)\n",
    "# y_pred = knclassifier.predict(X_test)\n",
    "\n",
    "# log_result('KNeighborsTimeSeriesClassifier',y_test, y_pred)\n",
    "\n",
    "# NO MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsTimeSeriesClassifier with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padded_KN_pipeline = ClassifierPipeline(\n",
    "#     KNeighborsTimeSeriesClassifier(n_neighbors=5, distance =\"dtw\", n_jobs= 1, leaf_size = 2000), \n",
    "#     [PaddingTransformer()]\n",
    "# )\n",
    "# padded_KN_pipeline.fit(X_train, y_train)\n",
    "# y_pred = padded_KN_pipeline.predict(X_test)\n",
    "\n",
    "# log_result('KNeighborsTimeSeriesClassifier',y_test, y_pred)\n",
    "\n",
    "# NO MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomIntervalClassifier\n",
    "extract at random interval and perform Rotation forest with 200 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.420168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 classifier  accuracy_score  AUC_score  F1_score\n",
       "0  RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1            IndividualBoss        0.252101   0.536985  0.252101\n",
       "2          ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3          time_series_tree        0.310924   0.578198  0.310924\n",
       "4  RandomIntervalClassifier        0.420168   0.700349  0.420168"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# otherwise, we have to use paddingtransformer to process the unequal length\n",
    "padded_clf = PaddingTransformer() * RandomIntervalClassifier(n_intervals=5, n_jobs=-1, random_state = 42)\n",
    "padded_clf.fit(X_train, y_train)\n",
    "y_pred_proba = padded_clf.predict_proba(X_test)\n",
    "\n",
    "log_result('RandomIntervalClassifier',padded_clf.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.420168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomIntervalClassifier_fit_rest</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          classifier  accuracy_score  AUC_score  F1_score\n",
       "0           RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1                     IndividualBoss        0.252101   0.536985  0.252101\n",
       "2                   ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3                   time_series_tree        0.310924   0.578198  0.310924\n",
       "4           RandomIntervalClassifier        0.420168   0.700349  0.420168\n",
       "5  RandomIntervalClassifier_fit_rest        0.247525   0.517295  0.247525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# otherwise, we have to use paddingtransformer to process the unequal length\n",
    "padded_clf = PaddingTransformer() * RandomIntervalClassifier(n_intervals=5, n_jobs=-1, random_state = 42)\n",
    "padded_clf.fit(X_fit_rest_train, y_fit_rest_train)\n",
    "y_fit_rest_pred_proba = padded_clf.predict_proba(X_fit_rest_test)\n",
    "\n",
    "log_result('RandomIntervalClassifier_fit_rest',padded_clf.classes_, y_fit_rest_test, y_fit_rest_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees with mean, std, slope\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    (\"padding\",PaddingTransformer()),\n",
    "    (\n",
    "        \"extract\",\n",
    "        RandomIntervalFeatureExtractor(\n",
    "            n_intervals=\"sqrt\", features=[np.mean, np.std, _slope]\n",
    "        ),\n",
    "    ),\n",
    "    (\"clf\", DecisionTreeClassifier()),\n",
    "]\n",
    "time_series_tree = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 classifier  accuracy_score  AUC_score  F1_score\n",
       "0  RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1            IndividualBoss        0.252101   0.536985  0.252101\n",
       "2          ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3          time_series_tree        0.310924   0.578198  0.310924"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_series_tree.fit(X_train, y_train)\n",
    "y_pred_proba = time_series_tree.predict_proba(X_test)\n",
    "log_result('time_series_tree',time_series_tree.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ComposableTimeSeriesForestClassifier\n",
    "https://www.sktime.org/en/v0.8.1/examples/02_classification_univariate.html\n",
    "\n",
    "## ON PAUSE CAUSE TAKES TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sktime.org/en/v0.8.1/examples/02_classification_univariate.html\n",
    "tsf_tst = PaddingTransformer() * ComposableTimeSeriesForestClassifier(\n",
    "    estimator=time_series_tree,\n",
    "    n_estimators=100,\n",
    "    # criterion=\"entropy\",\n",
    "    bootstrap=True,\n",
    "    oob_score=True,\n",
    "    random_state=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "tsf_tst.fit(X_train, y_train.astype(\"string\"))\n",
    "\n",
    "if tsf_tst.oob_score:\n",
    "    print(tsf.oob_score_)\n",
    "\n",
    "y_pred_proba = tsf_tst.predict_proba(X_test)\n",
    "\n",
    "log_result('tsf_time_series_forest',tsf_tst.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsf = ComposableTimeSeriesForestClassifier()\n",
    "tsf.fit(X_train, y_train)\n",
    "y_pred_proba = tsf.predict_proba(X_test)\n",
    "log_result('TimeSeriesForestClassifier',tsf.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using catch22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch22 = PaddingTransformer() * Catch22()\n",
    "X_train_catch22 = catch22.fit_transform(X_train)\n",
    "X_test_catch22 = catch22.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_catch22.to_csv(\"..\\\\cleanedData\\\\X_train_catch22.csv\")\n",
    "X_test_catch22.to_csv(\"..\\\\cleanedData\\\\X_test_catch22.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Boss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/sktime/sktime/issues/4090\n",
    "\n",
    "Proposed a bug fix to sktime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C:\\Users\\kyunomi\\anaconda3\\envs\\cogpilot\\Lib\\site-packages\\sktime\\classification\\dictionary_based\\_boss.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"C:\\Users\\kyunomi\\anaconda3\\envs\\cogpilot\\Lib\\site-packages\\sktime\\classification\\dictionary_based\\_boss.py\"\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"BOSS classifiers.\n",
    "\n",
    "Dictionary based BOSS classifiers based on SFA transform. Contains a single\n",
    "BOSS and a BOSS ensemble.\n",
    "\"\"\"\n",
    "\n",
    "__author__ = [\"MatthewMiddlehurst\", \"patrickzib\"]\n",
    "__all__ = [\"BOSSEnsemble\", \"IndividualBOSS\", \"pairwise_distances\"]\n",
    "\n",
    "import warnings\n",
    "from itertools import compress\n",
    "\n",
    "import numpy as np\n",
    "from joblib import Parallel, effective_n_jobs\n",
    "from sklearn.metrics import pairwise\n",
    "from sklearn.utils import check_random_state, gen_even_slices\n",
    "from sklearn.utils.extmath import safe_sparse_dot\n",
    "from sklearn.utils.fixes import delayed\n",
    "from sklearn.utils.sparsefuncs_fast import csr_row_norms\n",
    "from sklearn.utils.validation import _num_samples\n",
    "\n",
    "from sktime.classification.base import BaseClassifier\n",
    "from sktime.transformations.panel.dictionary_based import SFAFast\n",
    "from sktime.utils.validation.panel import check_X_y\n",
    "\n",
    "\n",
    "class BOSSEnsemble(BaseClassifier):\n",
    "    \"\"\"Ensemble of Bag of Symbolic Fourier Approximation Symbols (BOSS).\n",
    "\n",
    "    Implementation of BOSS Ensemble from Schfer (2015). [1]_\n",
    "\n",
    "    Overview: Input *n* series of length *m* and BOSS performs a grid search over\n",
    "    a set of parameter values, evaluating each with a LOOCV. It then retains\n",
    "    all ensemble members within 92% of the best by default for use in the ensemble.\n",
    "    There are three primary parameters:\n",
    "        - *alpha*: alphabet size\n",
    "        - *w*: window length\n",
    "        - *l*: word length.\n",
    "\n",
    "    For any combination, a single BOSS slides a window length *w* along the\n",
    "    series. The w length window is shortened to an *l* length word through\n",
    "    taking a Fourier transform and keeping the first *l/2* complex coefficients.\n",
    "    These *l* coefficients are then discretized into alpha possible values,\n",
    "    to form a word length *l*. A histogram of words for each\n",
    "    series is formed and stored.\n",
    "\n",
    "    Fit involves finding \"n\" histograms.\n",
    "\n",
    "    Predict uses 1 nearest neighbor with a bespoke BOSS distance function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float, default=0.92\n",
    "        Threshold used to determine which classifiers to retain. All classifiers\n",
    "        within percentage `threshold` of the best one are retained.\n",
    "    max_ensemble_size : int or None, default=500\n",
    "        Maximum number of classifiers to retain. Will limit number of retained\n",
    "        classifiers even if more than `max_ensemble_size` are within threshold.\n",
    "    max_win_len_prop : int or float, default=1\n",
    "        Maximum window length as a proportion of the series length.\n",
    "    min_window : int, default=10\n",
    "        Minimum window size.\n",
    "    typed_dict : bool, default=\"deprecated\"\n",
    "        Use a numba TypedDict to store word counts. May increase memory usage, but will\n",
    "        be faster for larger datasets. As the Dict cannot be pickled currently, there\n",
    "        will be some overhead converting it to a python dict with multiple threads and\n",
    "        pickling.\n",
    "\n",
    "        .. deprecated:: 0.13.3\n",
    "            ``typed_dict`` was deprecated in version 0.13.3 and will be removed in 0.15.\n",
    "\n",
    "    save_train_predictions : bool, default=False\n",
    "        Save the ensemble member train predictions in fit for use in _get_train_probs\n",
    "        leave-one-out cross-validation.\n",
    "    alphabet_size : default = 4\n",
    "        Number of possible letters (values) for each word.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    use_boss_distance : boolean, default=True\n",
    "        The Boss-distance is an asymmetric distance measure. It provides higher\n",
    "        accuracy, yet is signifaicantly slower to compute.\n",
    "    feature_selection: {\"chi2\", \"none\", \"random\"}, default: none\n",
    "        Sets the feature selections strategy to be used. Chi2 reduces the number\n",
    "        of words significantly and is thus much faster (preferred). Random also reduces\n",
    "        the number significantly. None applies not feature selectiona and yields large\n",
    "        bag of words, e.g. much memory may be needed.\n",
    "    random_state : int or None, default=None\n",
    "        Seed for random, integer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        Number of classes. Extracted from the data.\n",
    "    classes_ : list\n",
    "        The classes labels.\n",
    "    n_instances_ : int\n",
    "        Number of instances. Extracted from the data.\n",
    "    n_estimators_ : int\n",
    "        The final number of classifiers used. Will be <= `max_ensemble_size` if\n",
    "        `max_ensemble_size` has been specified.\n",
    "    series_length_ : int\n",
    "        Length of all series (assumed equal).\n",
    "    estimators_ : list\n",
    "       List of DecisionTree classifiers.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    IndividualBOSS, ContractableBOSS\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For the Java version, see\n",
    "    - `Original Publication <https://github.com/patrickzib/SFA>`_.\n",
    "    - `TSML <https://github.com/uea-machine-learning/tsml/blob/master/src/main/java/\n",
    "    tsml/classifiers/dictionary_based/BOSS.java>`_.\n",
    "\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Patrick Schfer, \"The BOSS is concerned with time series classification\n",
    "       in the presence of noise\", Data Mining and Knowledge Discovery, 29(6): 2015\n",
    "       https://link.springer.com/article/10.1007/s10618-014-0377-7\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sktime.classification.dictionary_based import BOSSEnsemble\n",
    "    >>> from sktime.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\", return_X_y=True)\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\", return_X_y=True)\n",
    "    >>> clf = BOSSEnsemble(max_ensemble_size=3)\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    BOSSEnsemble(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:train_estimate\": True,\n",
    "        \"capability:multithreading\": True,\n",
    "        \"classifier_type\": \"dictionary\",\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold=0.92,\n",
    "        max_ensemble_size=500,\n",
    "        max_win_len_prop=1,\n",
    "        min_window=10,\n",
    "        typed_dict=True,\n",
    "        save_train_predictions=False,\n",
    "        feature_selection=\"none\",\n",
    "        use_boss_distance=True,\n",
    "        alphabet_size=4,\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.threshold = threshold\n",
    "        self.max_ensemble_size = max_ensemble_size\n",
    "        self.max_win_len_prop = max_win_len_prop\n",
    "        self.min_window = min_window\n",
    "\n",
    "        self.typed_dict = typed_dict\n",
    "        self.save_train_predictions = save_train_predictions\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.use_boss_distance = use_boss_distance\n",
    "\n",
    "        self.estimators_ = []\n",
    "        self.n_estimators_ = 0\n",
    "        self.series_length_ = 0\n",
    "        self.n_instances_ = 0\n",
    "        self.feature_selection = feature_selection\n",
    "\n",
    "        self._word_lengths = [16, 14, 12, 10, 8]\n",
    "        self._norm_options = [True, False]\n",
    "        self.alphabet_size = alphabet_size\n",
    "\n",
    "        super(BOSSEnsemble, self).__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit a boss ensemble on cases (X,y), where y is the target variable.\n",
    "\n",
    "        Build an ensemble of BOSS classifiers from the training set (X,\n",
    "        y), through  creating a variable size ensemble of those within a\n",
    "        threshold of the best.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.array of shape = [n_instances, n_dimensions, series_length]\n",
    "            The training data.\n",
    "        y : array-like, shape = [n_instances]\n",
    "            The class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\" and sets is_fitted flag to True.\n",
    "        \"\"\"\n",
    "        self.n_instances_, _, self.series_length_ = X.shape\n",
    "\n",
    "        self.estimators_ = []\n",
    "\n",
    "        # Window length parameter space dependent on series length\n",
    "        max_window_searches = self.series_length_ / 4\n",
    "        max_window = int(self.series_length_ * self.max_win_len_prop)\n",
    "        win_inc = max(1, int((max_window - self.min_window) / max_window_searches))\n",
    "\n",
    "        if self.typed_dict != \"deprecated\":\n",
    "            warnings.warn(\n",
    "                \"``typed_dict`` was deprecated in version 0.13.3 and \"\n",
    "                \"will be removed in 0.15.\"\n",
    "            )\n",
    "\n",
    "        if self.min_window > max_window + 1:\n",
    "            raise ValueError(\n",
    "                f\"Error in BOSSEnsemble, min_window =\"\n",
    "                f\"{self.min_window} is bigger\"\n",
    "                f\" than max_window ={max_window}.\"\n",
    "                f\" Try set min_window to be smaller than series length in \"\n",
    "                f\"the constructor, but the classifier may not work at \"\n",
    "                f\"all with very short series\"\n",
    "            )\n",
    "        max_acc = -1\n",
    "        min_max_acc = -1\n",
    "        for normalise in self._norm_options:\n",
    "            for win_size in range(self.min_window, max_window + 1, win_inc):\n",
    "                # max_word_len = min(self.min_window - 2, self.word_lengths[0])\n",
    "                boss = IndividualBOSS(\n",
    "                    win_size,\n",
    "                    self._word_lengths[0],\n",
    "                    normalise,\n",
    "                    self.alphabet_size,\n",
    "                    save_words=True,\n",
    "                    use_boss_distance=self.use_boss_distance,\n",
    "                    feature_selection=self.feature_selection,\n",
    "                    n_jobs=self.n_jobs,\n",
    "                    random_state=self.random_state,\n",
    "                )\n",
    "                boss.fit(X, y)\n",
    "\n",
    "                best_classifier_for_win_size = boss\n",
    "                best_acc_for_win_size = -1\n",
    "\n",
    "                # the used word length may be shorter\n",
    "                best_word_len = boss._transformer.word_length\n",
    "\n",
    "                for n, word_len in enumerate(self._word_lengths):\n",
    "                    if n > 0 and word_len < boss._transformer.word_length:\n",
    "                        boss = boss._shorten_bags(word_len, y)\n",
    "\n",
    "                    boss._accuracy = self._individual_train_acc(\n",
    "                        boss, y, self.n_instances_, best_acc_for_win_size\n",
    "                    )\n",
    "\n",
    "                    if boss._accuracy >= best_acc_for_win_size:\n",
    "                        best_acc_for_win_size = boss._accuracy\n",
    "                        best_classifier_for_win_size = boss\n",
    "                        best_word_len = word_len\n",
    "\n",
    "                if self._include_in_ensemble(\n",
    "                    best_acc_for_win_size,\n",
    "                    max_acc,\n",
    "                    min_max_acc,\n",
    "                    len(self.estimators_),\n",
    "                ):\n",
    "                    best_classifier_for_win_size._clean()\n",
    "                    best_classifier_for_win_size._set_word_len(X, y, best_word_len)\n",
    "                    self.estimators_.append(best_classifier_for_win_size)\n",
    "\n",
    "                    if best_acc_for_win_size > max_acc:\n",
    "                        max_acc = best_acc_for_win_size\n",
    "                        self.estimators_ = list(\n",
    "                            compress(\n",
    "                                self.estimators_,\n",
    "                                [\n",
    "                                    classifier._accuracy >= max_acc * self.threshold\n",
    "                                    for c, classifier in enumerate(self.estimators_)\n",
    "                                ],\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                    min_max_acc, min_acc_ind = self._worst_ensemble_acc()\n",
    "\n",
    "                    if len(self.estimators_) > self.max_ensemble_size:\n",
    "                        if min_acc_ind > -1:\n",
    "                            del self.estimators_[min_acc_ind]\n",
    "                            min_max_acc, min_acc_ind = self._worst_ensemble_acc()\n",
    "\n",
    "        self.n_estimators_ = len(self.estimators_)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X) -> np.ndarray:\n",
    "        \"\"\"Predict class values of n instances in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.array of shape = [n_instances, n_dimensions, series_length]\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_instances]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        rng = check_random_state(self.random_state)\n",
    "        return np.array(\n",
    "            [\n",
    "                self.classes_[int(rng.choice(np.flatnonzero(prob == prob.max())))]\n",
    "                for prob in self.predict_proba(X)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def _predict_proba(self, X) -> np.ndarray:\n",
    "        \"\"\"Predict class probabilities for n instances in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.array of shape = [n_instances, n_dimensions, series_length]\n",
    "            The data to make predict probabilities for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_instances, n_classes_]\n",
    "            Predicted probabilities using the ordering in classes_.\n",
    "        \"\"\"\n",
    "        sums = np.zeros((X.shape[0], self.n_classes_))\n",
    "\n",
    "        for clf in self.estimators_:\n",
    "            preds = clf.predict(X)\n",
    "            for i in range(0, X.shape[0]):\n",
    "                sums[i, self._class_dictionary[preds[i]]] += 1\n",
    "        dists = sums / (np.ones(self.n_classes_) * self.n_estimators_)\n",
    "\n",
    "        return dists\n",
    "\n",
    "    def _include_in_ensemble(self, acc, max_acc, min_max_acc, size):\n",
    "        if acc >= max_acc * self.threshold:\n",
    "            if size >= self.max_ensemble_size:\n",
    "                return acc > min_max_acc\n",
    "            else:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def _worst_ensemble_acc(self):\n",
    "        min_acc = 1.0\n",
    "        min_acc_idx = -1\n",
    "\n",
    "        for c, classifier in enumerate(self.estimators_):\n",
    "            if classifier._accuracy < min_acc:\n",
    "                min_acc = classifier._accuracy\n",
    "                min_acc_idx = c\n",
    "\n",
    "        return min_acc, min_acc_idx\n",
    "\n",
    "    def _get_train_probs(self, X, y):\n",
    "        self.check_is_fitted()\n",
    "        X, y = check_X_y(X, y, coerce_to_numpy=True, enforce_univariate=True)\n",
    "\n",
    "        n_instances, _, series_length = X.shape\n",
    "\n",
    "        if n_instances != self.n_instances_ or series_length != self.series_length_:\n",
    "            raise ValueError(\n",
    "                \"n_instances, series_length mismatch. X should be \"\n",
    "                \"the same as the training data used in fit for generating train \"\n",
    "                \"probabilities.\"\n",
    "            )\n",
    "\n",
    "        results = np.zeros((n_instances, self.n_classes_))\n",
    "        divisors = np.zeros(n_instances)\n",
    "\n",
    "        if self.save_train_predictions:\n",
    "            for clf in self.estimators_:\n",
    "                preds = clf._train_predictions\n",
    "                for n, pred in enumerate(preds):\n",
    "                    results[n][self._class_dictionary[pred]] += 1\n",
    "                    divisors[n] += 1\n",
    "\n",
    "        else:\n",
    "            for i, clf in enumerate(self.estimators_):\n",
    "                if self._transformed_data.shape[1] > 0:\n",
    "                    distance_matrix = pairwise_distances(\n",
    "                        clf._transformed_data,\n",
    "                        use_boss_distance=self.use_boss_distance,\n",
    "                        n_jobs=self.n_jobs,\n",
    "                    )\n",
    "\n",
    "                    preds = []\n",
    "                    for i in range(n_instances):\n",
    "                        preds.append(clf._train_predict(i, distance_matrix))\n",
    "\n",
    "                    for n, pred in enumerate(preds):\n",
    "                        results[n][self._class_dictionary[pred]] += 1\n",
    "                        divisors[n] += 1\n",
    "\n",
    "        for i in range(n_instances):\n",
    "            results[i] = (\n",
    "                np.ones(self.n_classes_) * (1 / self.n_classes_)\n",
    "                if divisors[i] == 0\n",
    "                else results[i] / (np.ones(self.n_classes_) * divisors[i])\n",
    "            )\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _individual_train_acc(self, boss, y, train_size, lowest_acc):\n",
    "        correct = 0\n",
    "        required_correct = int(lowest_acc * train_size)\n",
    "\n",
    "        # there may be no words if feature selection is too aggressive\n",
    "        if boss._transformed_data.shape[1] > 0:\n",
    "            distance_matrix = pairwise_distances(\n",
    "                boss._transformed_data,\n",
    "                use_boss_distance=self.use_boss_distance,\n",
    "                n_jobs=self.n_jobs,\n",
    "            )\n",
    "\n",
    "            for i in range(train_size):\n",
    "                if correct + train_size - i < required_correct:\n",
    "                    return -1\n",
    "\n",
    "                c = boss._train_predict(i, distance_matrix)\n",
    "                if c == y[i]:\n",
    "                    correct += 1\n",
    "\n",
    "                if self.save_train_predictions:\n",
    "                    boss._train_predictions.append(c)\n",
    "\n",
    "        return correct / train_size\n",
    "\n",
    "    @classmethod\n",
    "    def get_test_params(cls, parameter_set=\"default\"):\n",
    "        \"\"\"Return testing parameter settings for the estimator.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parameter_set : str, default=\"default\"\n",
    "            Name of the set of test parameters to return, for use in tests. If no\n",
    "            special parameters are defined for a value, will return `\"default\"` set.\n",
    "            For classifiers, a \"default\" set of parameters should be provided for\n",
    "            general testing, and a \"results_comparison\" set for comparing against\n",
    "            previously recorded results if the general set does not produce suitable\n",
    "            probabilities to compare against.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        params : dict or list of dict, default={}\n",
    "            Parameters to create testing instances of the class.\n",
    "            Each dict are parameters to construct an \"interesting\" test instance, i.e.,\n",
    "            `MyClass(**params)` or `MyClass(**params[i])` creates a valid test instance.\n",
    "            `create_test_instance` uses the first (or only) dictionary in `params`.\n",
    "        \"\"\"\n",
    "        if parameter_set == \"results_comparison\":\n",
    "            return {\n",
    "                \"max_ensemble_size\": 5,\n",
    "                \"feature_selection\": \"none\",\n",
    "                \"use_boss_distance\": False,\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"max_ensemble_size\": 2,\n",
    "                \"save_train_predictions\": True,\n",
    "                \"feature_selection\": \"none\",\n",
    "                \"use_boss_distance\": False,\n",
    "            }\n",
    "\n",
    "\n",
    "class IndividualBOSS(BaseClassifier):\n",
    "    \"\"\"Single bag of Symbolic Fourier Approximation Symbols (IndividualBOSS).\n",
    "\n",
    "    Bag of SFA Symbols Ensemble: implementation of a single BOSS Schaffer, the base\n",
    "    classifier for the boss ensemble.\n",
    "\n",
    "    Implementation of single BOSS model from Schfer (2015). [1]_\n",
    "\n",
    "    This is the underlying classifier for each classifier in the BOSS ensemble.\n",
    "\n",
    "    Overview: input \"n\" series of length \"m\" and IndividualBoss performs a SFA\n",
    "    transform to form a sparse dictionary of discretised words. The resulting\n",
    "    dictionary is used with the BOSS distance function in a 1-nearest neighbor.\n",
    "\n",
    "    Fit involves finding \"n\" histograms.\n",
    "\n",
    "    Predict uses 1 nearest neighbor with a bespoke BOSS distance function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    window_size : int\n",
    "        Size of the window to use in BOSS algorithm.\n",
    "    word_length : int\n",
    "        Length of word to use to use in BOSS algorithm.\n",
    "    norm : bool, default = False\n",
    "        Whether to normalize words by dropping the first Fourier coefficient.\n",
    "    alphabet_size : default = 4\n",
    "        Number of possible letters (values) for each word.\n",
    "    save_words : bool, default = True\n",
    "        Whether to keep NumPy array of words in SFA transformation even after\n",
    "        the dictionary of words is returned. If True, the array is saved, which\n",
    "        can shorten the time to calculate dictionaries using a shorter\n",
    "        `word_length` (since the last \"n\" letters can be removed).\n",
    "    typed_dict : bool, default=\"deprecated\"\n",
    "        Use a numba TypedDict to store word counts. May increase memory usage, but will\n",
    "        be faster for larger datasets. As the Dict cannot be pickled currently, there\n",
    "        will be some overhead converting it to a python dict with multiple threads and\n",
    "        pickling.\n",
    "\n",
    "        .. deprecated:: 0.13.3\n",
    "            ``typed_dict`` was deprecated in version 0.13.3 and will be removed in 0.15.\n",
    "    n_jobs : int, default=1\n",
    "        The number of jobs to run in parallel for both `fit` and `predict`.\n",
    "        ``-1`` means using all processors.\n",
    "    random_state : int or None, default=None\n",
    "        Seed for random, integer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_classes_ : int\n",
    "        Number of classes. Extracted from the data.\n",
    "    classes_ : list\n",
    "        The classes labels.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    BOSSEnsemble, ContractableBOSS\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    For the Java version, see\n",
    "    `TSML <https://github.com/uea-machine-learning/tsml/blob/master/src/main/java/\n",
    "    tsml/classifiers/dictionary_based/IndividualBOSS.java>`_.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Patrick Schfer, \"The BOSS is concerned with time series classification\n",
    "       in the presence of noise\", Data Mining and Knowledge Discovery, 29(6): 2015\n",
    "       https://link.springer.com/article/10.1007/s10618-014-0377-7\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sktime.classification.dictionary_based import IndividualBOSS\n",
    "    >>> from sktime.datasets import load_unit_test\n",
    "    >>> X_train, y_train = load_unit_test(split=\"train\", return_X_y=True)\n",
    "    >>> X_test, y_test = load_unit_test(split=\"test\", return_X_y=True)\n",
    "    >>> clf = IndividualBOSS()\n",
    "    >>> clf.fit(X_train, y_train)\n",
    "    IndividualBOSS(...)\n",
    "    >>> y_pred = clf.predict(X_test)\n",
    "    \"\"\"\n",
    "\n",
    "    _tags = {\n",
    "        \"capability:multithreading\": True,\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        window_size=10,\n",
    "        word_length=8,\n",
    "        norm=False,\n",
    "        alphabet_size=4,\n",
    "        save_words=False,\n",
    "        typed_dict=\"deprecated\",\n",
    "        use_boss_distance=True,\n",
    "        feature_selection=\"none\",\n",
    "        n_jobs=1,\n",
    "        random_state=None,\n",
    "    ):\n",
    "        self.window_size = window_size\n",
    "        self.word_length = word_length\n",
    "        self.norm = norm\n",
    "        self.alphabet_size = alphabet_size\n",
    "        self.feature_selection = feature_selection\n",
    "        self.use_boss_distance = use_boss_distance\n",
    "\n",
    "        self.save_words = save_words\n",
    "        self.typed_dict = typed_dict\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "\n",
    "        self._transformer = None\n",
    "        self._transformed_data = []\n",
    "        self._class_vals = []\n",
    "        self._accuracy = 0\n",
    "        self._subsample = []\n",
    "        self._train_predictions = []\n",
    "\n",
    "        super(IndividualBOSS, self).__init__()\n",
    "\n",
    "    def _fit(self, X, y):\n",
    "        \"\"\"Fit a single boss classifier on n_instances cases (X,y).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.array of shape = [n_instances, n_dimensions, series_length]\n",
    "            The training data.\n",
    "        y : array-like, shape = [n_instances]\n",
    "            The class labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self :\n",
    "            Reference to self.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Changes state by creating a fitted model that updates attributes\n",
    "        ending in \"_\" and sets is_fitted flag to True.\n",
    "        \"\"\"\n",
    "        self._transformer = SFAFast(\n",
    "            word_length=self.word_length,\n",
    "            alphabet_size=self.alphabet_size,\n",
    "            window_size=self.window_size,\n",
    "            norm=self.norm,\n",
    "            bigrams=False,\n",
    "            remove_repeat_words=True,\n",
    "            save_words=self.save_words,\n",
    "            n_jobs=self.n_jobs,\n",
    "            feature_selection=self.feature_selection,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "\n",
    "        self._transformed_data = self._transformer.fit_transform(X, y)\n",
    "        self._class_vals = y\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"Predict class values of all instances in X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 3D np.array of shape = [n_instances, n_dimensions, series_length]\n",
    "            The data to make predictions for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : array-like, shape = [n_instances]\n",
    "            Predicted class labels.\n",
    "        \"\"\"\n",
    "        test_bags = self._transformer.transform(X)\n",
    "        if data_type == np.str_:\n",
    "            data_type = \"object\"\n",
    "\n",
    "        classes = np.zeros(test_bags.shape[0], dtype=data_type)        \n",
    "        # classes = np.zeros(test_bags.shape[0], dtype=type(self._class_vals[0]))\n",
    "\n",
    "        if self._transformed_data.shape[1] > 0:\n",
    "            distance_matrix = pairwise_distances(\n",
    "                test_bags,\n",
    "                self._transformed_data,\n",
    "                use_boss_distance=self.use_boss_distance,\n",
    "                n_jobs=self.n_jobs,\n",
    "            )\n",
    "\n",
    "            for i in range(test_bags.shape[0]):\n",
    "                min_pos = np.argmin(distance_matrix[i])\n",
    "                classes[i] = self._class_vals[min_pos]\n",
    "        else:\n",
    "            # set to most frequent element\n",
    "            counts = np.bincount(self._class_vals)\n",
    "            classes[:] = np.argmax(counts)\n",
    "\n",
    "        return classes\n",
    "\n",
    "    def _train_predict(self, train_num, distance_matrix):\n",
    "        distance_vector = distance_matrix[train_num]\n",
    "        min_pos = np.argmin(distance_vector)\n",
    "        return self._class_vals[min_pos]\n",
    "\n",
    "    def _shorten_bags(self, word_len, y):\n",
    "        new_boss = IndividualBOSS(\n",
    "            self.window_size,\n",
    "            word_len,\n",
    "            self.norm,\n",
    "            self.alphabet_size,\n",
    "            save_words=self.save_words,\n",
    "            use_boss_distance=self.use_boss_distance,\n",
    "            feature_selection=self.feature_selection,\n",
    "            n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        new_boss._transformer = self._transformer\n",
    "        new_bag = new_boss._transformer._shorten_bags(word_len, y)\n",
    "        new_boss._transformed_data = new_bag\n",
    "        new_boss._class_vals = self._class_vals\n",
    "        new_boss.n_classes_ = self.n_classes_\n",
    "        new_boss.classes_ = self.classes_\n",
    "        new_boss._class_dictionary = self._class_dictionary\n",
    "        new_boss._is_fitted = True\n",
    "\n",
    "        return new_boss\n",
    "\n",
    "    def _clean(self):\n",
    "        self._transformer.words = None\n",
    "        self._transformer.save_words = False\n",
    "\n",
    "    def _set_word_len(self, X, y, word_len):\n",
    "        self.word_length = word_len\n",
    "\n",
    "        # we have to retrain feature selection for now\n",
    "        # might be optimized by remembering feature_dicts\n",
    "        self._transformer.word_length = min(self._transformer.word_length, word_len)\n",
    "        self._transformed_data = self._transformer.fit_transform(X, y)\n",
    "\n",
    "\n",
    "def _dist_wrapper(dist_matrix, X, Y, s, XX_all=None, XY_all=None):\n",
    "    \"\"\"Write in-place to a slice of a distance matrix.\"\"\"\n",
    "    for i in range(s.start, s.stop):\n",
    "        dist_matrix[i] = boss_distance(X, Y, i, XX_all, XY_all)\n",
    "\n",
    "\n",
    "def pairwise_distances(X, Y=None, use_boss_distance=False, n_jobs=1):\n",
    "    \"\"\"Find the euclidean distance between all pairs of bop-models.\"\"\"\n",
    "    if use_boss_distance:\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "\n",
    "        XX_row_norms = csr_row_norms(X)\n",
    "        XY = safe_sparse_dot(X, Y.T, dense_output=True)\n",
    "\n",
    "        distance_matrix = np.zeros((X.shape[0], Y.shape[0]))\n",
    "\n",
    "        if effective_n_jobs(n_jobs) > 1:\n",
    "            Parallel(n_jobs=n_jobs, backend=\"threading\")(\n",
    "                delayed(_dist_wrapper)(distance_matrix, X, Y, s, XX_row_norms, XY)\n",
    "                for s in gen_even_slices(_num_samples(X), effective_n_jobs(n_jobs))\n",
    "            )\n",
    "        else:\n",
    "            for i in range(len(distance_matrix)):\n",
    "                distance_matrix[i] = boss_distance(X, Y, i, XX_row_norms, XY)\n",
    "\n",
    "    else:\n",
    "        distance_matrix = pairwise.pairwise_distances(X, Y, n_jobs=n_jobs)\n",
    "\n",
    "    if X is Y or Y is None:\n",
    "        np.fill_diagonal(distance_matrix, np.inf)\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "\n",
    "# @njit(cache=True, fastmath=True)\n",
    "def boss_distance(X, Y, i, XX_all=None, XY_all=None):\n",
    "    \"\"\"Find the distance between two histograms.\n",
    "\n",
    "    This returns the distance between first and second dictionaries, using a non-\n",
    "    symmetric distance measure. It is used to find the distance between historgrams\n",
    "    of words.\n",
    "\n",
    "    This distance function is designed for sparse matrix, represented as either a\n",
    "    dictionary or an arrray. It only measures the distance between counts present in\n",
    "    the first dictionary and the second. Hence dist(a,b) does not necessarily equal\n",
    "    dist(b,a).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : sparse matrix\n",
    "        Base dictionary used in distance measurement.\n",
    "    Y : sparse matrix\n",
    "        Second dictionary that will be used to measure distance from `first`.\n",
    "    i : int\n",
    "        index of current element\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist : float\n",
    "        The boss distance between the first and second dictionaries.\n",
    "    \"\"\"\n",
    "    mask = X[i].nonzero()[1]\n",
    "    if XX_all is None:\n",
    "        XX = csr_row_norms(X[i])\n",
    "    else:\n",
    "        XX = XX_all[i]\n",
    "    if XY_all is None:\n",
    "        XY = safe_sparse_dot(X[i], Y.T, dense_output=True)\n",
    "    else:\n",
    "        XY = XY_all[i]\n",
    "\n",
    "    YY = csr_row_norms(Y[:, mask])\n",
    "    A = XX - 2 * XY + YY\n",
    "    np.maximum(A, 0, out=A)\n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 classifier  accuracy_score  AUC_score  F1_score\n",
       "0  RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1            IndividualBoss        0.252101   0.536985  0.252101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iboss = PaddingTransformer() * IndividualBOSS()\n",
    "iboss.fit(X_train, y_train)\n",
    "y_pred_proba = iboss.predict_proba(X_test)\n",
    "\n",
    "log_result('IndividualBoss',iboss.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ContractableBoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 classifier  accuracy_score  AUC_score  F1_score\n",
       "0  RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1            IndividualBoss        0.252101   0.536985  0.252101\n",
       "2          ContractableBOSS        0.294118   0.571395  0.294118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cboss = PaddingTransformer() * ContractableBOSS(n_parameter_samples=10, max_ensemble_size=3)\n",
    "cboss.fit(X_train, y_train)\n",
    "y_pred_proba = cboss.predict_proba(X_test)\n",
    "\n",
    "log_result('ContractableBOSS',cboss.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Interval Spectral Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.420168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomIntervalClassifier_fit_rest</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RISE</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          classifier  accuracy_score  AUC_score  F1_score\n",
       "0           RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1                     IndividualBoss        0.252101   0.536985  0.252101\n",
       "2                   ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3                   time_series_tree        0.310924   0.578198  0.310924\n",
       "4           RandomIntervalClassifier        0.420168   0.700349  0.420168\n",
       "5  RandomIntervalClassifier_fit_rest        0.247525   0.517295  0.247525\n",
       "6                               RISE        0.369748   0.713467  0.369748"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rise = PaddingTransformer() * RandomIntervalSpectralEnsemble(n_estimators=50, random_state=42)\n",
    "rise.fit(X_train, y_train)\n",
    "y_pred_proba = rise.predict_proba(X_test)\n",
    "\n",
    "log_result('RISE',rise.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Time Series Forest (STSF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.420168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomIntervalClassifier_fit_rest</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RISE</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dr_Cif</td>\n",
       "      <td>0.436975</td>\n",
       "      <td>0.717640</td>\n",
       "      <td>0.436975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>STSF</td>\n",
       "      <td>0.453782</td>\n",
       "      <td>0.719416</td>\n",
       "      <td>0.453782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          classifier  accuracy_score  AUC_score  F1_score\n",
       "0           RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1                     IndividualBoss        0.252101   0.536985  0.252101\n",
       "2                   ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3                   time_series_tree        0.310924   0.578198  0.310924\n",
       "4           RandomIntervalClassifier        0.420168   0.700349  0.420168\n",
       "5  RandomIntervalClassifier_fit_rest        0.247525   0.517295  0.247525\n",
       "6                               RISE        0.369748   0.713467  0.369748\n",
       "7                             Dr_Cif        0.436975   0.717640  0.436975\n",
       "8                               STSF        0.453782   0.719416  0.453782"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stsf = PaddingTransformer() * SupervisedTimeSeriesForest(n_estimators=50, random_state=42)\n",
    "stsf.fit(X_train, y_train)\n",
    "y_pred_proba = stsf.predict_proba(X_test)\n",
    "\n",
    "log_result('STSF',stsf.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canonical Interval Forest (CIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIF</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.664489</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy_score  AUC_score  F1_score\n",
       "0        CIF        0.361345   0.664489  0.361345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cif = PaddingTransformer() * CanonicalIntervalForest(n_estimators=5, att_subsample_size=10, random_state=42)\n",
    "cif.fit(X_train, y_train)\n",
    "y_pred_proba = cif.predict_proba(X_test)\n",
    "\n",
    "log_result('CIF',cif.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diverse Representation Canonical Interval Forest (DrCIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IndividualBoss</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.536985</td>\n",
       "      <td>0.252101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ContractableBOSS</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.571395</td>\n",
       "      <td>0.294118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_series_tree</td>\n",
       "      <td>0.310924</td>\n",
       "      <td>0.578198</td>\n",
       "      <td>0.310924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomIntervalClassifier</td>\n",
       "      <td>0.420168</td>\n",
       "      <td>0.700349</td>\n",
       "      <td>0.420168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomIntervalClassifier_fit_rest</td>\n",
       "      <td>0.247525</td>\n",
       "      <td>0.517295</td>\n",
       "      <td>0.247525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RISE</td>\n",
       "      <td>0.369748</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.369748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dr_Cif</td>\n",
       "      <td>0.436975</td>\n",
       "      <td>0.717640</td>\n",
       "      <td>0.436975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          classifier  accuracy_score  AUC_score  F1_score\n",
       "0           RandomIntervalClassifier        0.252101   0.536985  0.252101\n",
       "1                     IndividualBoss        0.252101   0.536985  0.252101\n",
       "2                   ContractableBOSS        0.294118   0.571395  0.294118\n",
       "3                   time_series_tree        0.310924   0.578198  0.310924\n",
       "4           RandomIntervalClassifier        0.420168   0.700349  0.420168\n",
       "5  RandomIntervalClassifier_fit_rest        0.247525   0.517295  0.247525\n",
       "6                               RISE        0.369748   0.713467  0.369748\n",
       "7                             Dr_Cif        0.436975   0.717640  0.436975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dr_cif = PaddingTransformer() * DrCIF(n_estimators=5, att_subsample_size=10, random_state=42)\n",
    "dr_cif.fit(X_train, y_train)\n",
    "y_pred_proba = dr_cif.predict_proba(X_test)\n",
    "\n",
    "log_result('Dr_Cif',dr_cif.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShapeletTransformClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIF</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.664489</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShapeletTransformClassifier</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.469264</td>\n",
       "      <td>0.243697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    classifier  accuracy_score  AUC_score  F1_score\n",
       "0                          CIF        0.361345   0.664489  0.361345\n",
       "1  ShapeletTransformClassifier        0.243697   0.469264  0.243697"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stc = PaddingTransformer() * ShapeletTransformClassifier(\n",
    "    estimator=RotationForest(n_estimators=3),\n",
    "    n_shapelet_samples=100,\n",
    "    max_shapelets=10,\n",
    "    batch_size=20,\n",
    ")\n",
    "stc.fit(X_train, y_train)\n",
    "y_pred_proba = stc.predict_proba(X_test)\n",
    "\n",
    "log_result('ShapeletTransformClassifier',stc.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RocketClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>AUC_score</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIF</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.664489</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ShapeletTransformClassifier</td>\n",
       "      <td>0.243697</td>\n",
       "      <td>0.469264</td>\n",
       "      <td>0.243697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RocketClassifier</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>0.620612</td>\n",
       "      <td>0.361345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    classifier  accuracy_score  AUC_score  F1_score\n",
       "0                          CIF        0.361345   0.664489  0.361345\n",
       "1  ShapeletTransformClassifier        0.243697   0.469264  0.243697\n",
       "2             RocketClassifier        0.361345   0.620612  0.361345"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocket = PaddingTransformer() * RocketClassifier(num_kernels=500)\n",
    "rocket.fit(X_train, y_train)\n",
    "y_pred_proba = rocket.predict_proba(X_test)\n",
    "\n",
    "log_result('RocketClassifier',rocket.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HIVECOTEV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hivecotev = PaddingTransformer() * HIVECOTEV1()\n",
    "hivecotev.fit(X_train, y_train)\n",
    "y_pred_proba = hivecotev.predict_proba(X_test)\n",
    "\n",
    "log_result('HIVECOTEV1',hivecotev.classes_, y_test, y_pred_proba)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try looking\n",
    "- filter out different subject with different resp hz then do training for them.\n",
    "- do gridsearch using genetic to improve result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogpilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a6363372e1d778c4137ad4a53928cfc69136b01ab6f02bce312c553d9eae285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
