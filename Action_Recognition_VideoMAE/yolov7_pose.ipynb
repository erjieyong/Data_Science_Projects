{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9rdE93cZOVV"
      },
      "source": [
        "# Prepare dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfnqbFjlYh84",
        "outputId": "6992cb16-a145-4c87-e406-fc876ea04004"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/detectron2.git'\"\n"
          ]
        }
      ],
      "source": [
        "#Needed for yolov7 to work\n",
        "! pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94897vaSYusG",
        "outputId": "96cff058-a744-44e6-f5ed-1faabd21d48b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'yolov7' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#download yolov7 github\n",
        "!git clone https://github.com/WongKinYiu/yolov7.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AijtP7cKY5lR",
        "outputId": "1f95fba6-820c-4f79-f765-bea4322a5706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kyunomi\\Desktop\\lauretta\\yolov7_pose\\yolov7\n"
          ]
        }
      ],
      "source": [
        "# download pretrained weight\n",
        "%cd yolov7\n",
        "# !wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-w6-pose.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ubw6-hzPdbsC",
        "outputId": "99d92feb-44a6-4e92-9f2c-23b745a2f49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils/plots.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile utils/plots.py\n",
        "# Plotting utils\n",
        "# edited plots.py based on https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/#YOLOv7-vs-MediaPipe-Pose-Features\n",
        "\n",
        "import glob\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "from copy import copy\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import yaml\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "from utils.general import xywh2xyxy, xyxy2xywh\n",
        "from utils.metrics import fitness\n",
        "\n",
        "# Settings\n",
        "matplotlib.rc('font', **{'size': 11})\n",
        "matplotlib.use('Agg')  # for writing to files only\n",
        "\n",
        "\n",
        "def color_list():\n",
        "    # Return first 10 plt colors as (r,g,b) https://stackoverflow.com/questions/51350872/python-from-color-name-to-rgb\n",
        "    def hex2rgb(h):\n",
        "        return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))\n",
        "\n",
        "    return [hex2rgb(h) for h in matplotlib.colors.TABLEAU_COLORS.values()]  # or BASE_ (8), CSS4_ (148), XKCD_ (949)\n",
        "\n",
        "\n",
        "def hist2d(x, y, n=100):\n",
        "    # 2d histogram used in labels.png and evolve.png\n",
        "    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)\n",
        "    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))\n",
        "    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)\n",
        "    yidx = np.clip(np.digitize(y, yedges) - 1, 0, hist.shape[1] - 1)\n",
        "    return np.log(hist[xidx, yidx])\n",
        "\n",
        "\n",
        "def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):\n",
        "    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy\n",
        "    def butter_lowpass(cutoff, fs, order):\n",
        "        nyq = 0.5 * fs\n",
        "        normal_cutoff = cutoff / nyq\n",
        "        return butter(order, normal_cutoff, btype='low', analog=False)\n",
        "\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    return filtfilt(b, a, data)  # forward-backward filter\n",
        "\n",
        "\n",
        "def plot_one_box(x, img, color=None, label=None, line_thickness=3):\n",
        "    # Plots one bounding box on image img\n",
        "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
        "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
        "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
        "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
        "    if label:\n",
        "        tf = max(tl - 1, 1)  # font thickness\n",
        "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
        "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
        "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
        "\n",
        "\n",
        "def plot_one_box_PIL(box, img, color=None, label=None, line_thickness=None):\n",
        "    img = Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    line_thickness = line_thickness or max(int(min(img.size) / 200), 2)\n",
        "    draw.rectangle(box, width=line_thickness, outline=tuple(color))  # plot\n",
        "    if label:\n",
        "        fontsize = max(round(max(img.size) / 40), 12)\n",
        "        font = ImageFont.truetype(\"Arial.ttf\", fontsize)\n",
        "        txt_width, txt_height = font.getsize(label)\n",
        "        draw.rectangle([box[0], box[1] - txt_height + 4, box[0] + txt_width, box[1]], fill=tuple(color))\n",
        "        draw.text((box[0], box[1] - txt_height + 1), label, fill=(255, 255, 255), font=font)\n",
        "    return np.asarray(img)\n",
        "\n",
        "\n",
        "def plot_wh_methods():  # from utils.plots import *; plot_wh_methods()\n",
        "    # Compares the two methods for width-height anchor multiplication\n",
        "    # https://github.com/ultralytics/yolov3/issues/168\n",
        "    x = np.arange(-4.0, 4.0, .1)\n",
        "    ya = np.exp(x)\n",
        "    yb = torch.sigmoid(torch.from_numpy(x)).numpy() * 2\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 3), tight_layout=True)\n",
        "    plt.plot(x, ya, '.-', label='YOLOv3')\n",
        "    plt.plot(x, yb ** 2, '.-', label='YOLOR ^2')\n",
        "    plt.plot(x, yb ** 1.6, '.-', label='YOLOR ^1.6')\n",
        "    plt.xlim(left=-4, right=4)\n",
        "    plt.ylim(bottom=0, top=6)\n",
        "    plt.xlabel('input')\n",
        "    plt.ylabel('output')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "    fig.savefig('comparison.png', dpi=200)\n",
        "\n",
        "\n",
        "def output_to_target(output):\n",
        "    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]\n",
        "    targets = []\n",
        "    for i, o in enumerate(output):\n",
        "        for *box, conf, cls in o.cpu().numpy():\n",
        "            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf])\n",
        "    return np.array(targets)\n",
        "\n",
        "\n",
        "def plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=640, max_subplots=16):\n",
        "    # Plot image grid with labels\n",
        "\n",
        "    if isinstance(images, torch.Tensor):\n",
        "        images = images.cpu().float().numpy()\n",
        "    if isinstance(targets, torch.Tensor):\n",
        "        targets = targets.cpu().numpy()\n",
        "\n",
        "    # un-normalise\n",
        "    if np.max(images[0]) <= 1:\n",
        "        images *= 255\n",
        "\n",
        "    tl = 3  # line thickness\n",
        "    tf = max(tl - 1, 1)  # font thickness\n",
        "    bs, _, h, w = images.shape  # batch size, _, height, width\n",
        "    bs = min(bs, max_subplots)  # limit plot images\n",
        "    ns = np.ceil(bs ** 0.5)  # number of subplots (square)\n",
        "\n",
        "    # Check if we should resize\n",
        "    scale_factor = max_size / max(h, w)\n",
        "    if scale_factor < 1:\n",
        "        h = math.ceil(scale_factor * h)\n",
        "        w = math.ceil(scale_factor * w)\n",
        "\n",
        "    colors = color_list()  # list of colors\n",
        "    mosaic = np.full((int(ns * h), int(ns * w), 3), 255, dtype=np.uint8)  # init\n",
        "    for i, img in enumerate(images):\n",
        "        if i == max_subplots:  # if last batch has fewer images than we expect\n",
        "            break\n",
        "\n",
        "        block_x = int(w * (i // ns))\n",
        "        block_y = int(h * (i % ns))\n",
        "\n",
        "        img = img.transpose(1, 2, 0)\n",
        "        if scale_factor < 1:\n",
        "            img = cv2.resize(img, (w, h))\n",
        "\n",
        "        mosaic[block_y:block_y + h, block_x:block_x + w, :] = img\n",
        "        if len(targets) > 0:\n",
        "            image_targets = targets[targets[:, 0] == i]\n",
        "            boxes = xywh2xyxy(image_targets[:, 2:6]).T\n",
        "            classes = image_targets[:, 1].astype('int')\n",
        "            labels = image_targets.shape[1] == 6  # labels if no conf column\n",
        "            conf = None if labels else image_targets[:, 6]  # check for confidence presence (label vs pred)\n",
        "\n",
        "            if boxes.shape[1]:\n",
        "                if boxes.max() <= 1.01:  # if normalized with tolerance 0.01\n",
        "                    boxes[[0, 2]] *= w  # scale to pixels\n",
        "                    boxes[[1, 3]] *= h\n",
        "                elif scale_factor < 1:  # absolute coords need scale if image scales\n",
        "                    boxes *= scale_factor\n",
        "            boxes[[0, 2]] += block_x\n",
        "            boxes[[1, 3]] += block_y\n",
        "            for j, box in enumerate(boxes.T):\n",
        "                cls = int(classes[j])\n",
        "                color = colors[cls % len(colors)]\n",
        "                cls = names[cls] if names else cls\n",
        "                if labels or conf[j] > 0.25:  # 0.25 conf thresh\n",
        "                    label = '%s' % cls if labels else '%s %.1f' % (cls, conf[j])\n",
        "                    plot_one_box(box, mosaic, label=label, color=color, line_thickness=tl)\n",
        "\n",
        "        # Draw image filename labels\n",
        "        if paths:\n",
        "            label = Path(paths[i]).name[:40]  # trim to 40 char\n",
        "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
        "            cv2.putText(mosaic, label, (block_x + 5, block_y + t_size[1] + 5), 0, tl / 3, [220, 220, 220], thickness=tf,\n",
        "                        lineType=cv2.LINE_AA)\n",
        "\n",
        "        # Image border\n",
        "        cv2.rectangle(mosaic, (block_x, block_y), (block_x + w, block_y + h), (255, 255, 255), thickness=3)\n",
        "\n",
        "    if fname:\n",
        "        r = min(1280. / max(h, w) / ns, 1.0)  # ratio to limit image size\n",
        "        mosaic = cv2.resize(mosaic, (int(ns * w * r), int(ns * h * r)), interpolation=cv2.INTER_AREA)\n",
        "        # cv2.imwrite(fname, cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB))  # cv2 save\n",
        "        Image.fromarray(mosaic).save(fname)  # PIL save\n",
        "    return mosaic\n",
        "\n",
        "\n",
        "def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=''):\n",
        "    # Plot LR simulating training for full epochs\n",
        "    optimizer, scheduler = copy(optimizer), copy(scheduler)  # do not modify originals\n",
        "    y = []\n",
        "    for _ in range(epochs):\n",
        "        scheduler.step()\n",
        "        y.append(optimizer.param_groups[0]['lr'])\n",
        "    plt.plot(y, '.-', label='LR')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('LR')\n",
        "    plt.grid()\n",
        "    plt.xlim(0, epochs)\n",
        "    plt.ylim(0)\n",
        "    plt.savefig(Path(save_dir) / 'LR.png', dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_test_txt():  # from utils.plots import *; plot_test()\n",
        "    # Plot test.txt histograms\n",
        "    x = np.loadtxt('test.txt', dtype=np.float32)\n",
        "    box = xyxy2xywh(x[:, :4])\n",
        "    cx, cy = box[:, 0], box[:, 1]\n",
        "\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)\n",
        "    ax.hist2d(cx, cy, bins=600, cmax=10, cmin=0)\n",
        "    ax.set_aspect('equal')\n",
        "    plt.savefig('hist2d.png', dpi=300)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6), tight_layout=True)\n",
        "    ax[0].hist(cx, bins=600)\n",
        "    ax[1].hist(cy, bins=600)\n",
        "    plt.savefig('hist1d.png', dpi=200)\n",
        "\n",
        "\n",
        "def plot_targets_txt():  # from utils.plots import *; plot_targets_txt()\n",
        "    # Plot targets.txt histograms\n",
        "    x = np.loadtxt('targets.txt', dtype=np.float32).T\n",
        "    s = ['x targets', 'y targets', 'width targets', 'height targets']\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)\n",
        "    ax = ax.ravel()\n",
        "    for i in range(4):\n",
        "        ax[i].hist(x[i], bins=100, label='%.3g +/- %.3g' % (x[i].mean(), x[i].std()))\n",
        "        ax[i].legend()\n",
        "        ax[i].set_title(s[i])\n",
        "    plt.savefig('targets.jpg', dpi=200)\n",
        "\n",
        "\n",
        "def plot_study_txt(path='', x=None):  # from utils.plots import *; plot_study_txt()\n",
        "    # Plot study.txt generated by test.py\n",
        "    fig, ax = plt.subplots(2, 4, figsize=(10, 6), tight_layout=True)\n",
        "    # ax = ax.ravel()\n",
        "\n",
        "    fig2, ax2 = plt.subplots(1, 1, figsize=(8, 4), tight_layout=True)\n",
        "    # for f in [Path(path) / f'study_coco_{x}.txt' for x in ['yolor-p6', 'yolor-w6', 'yolor-e6', 'yolor-d6']]:\n",
        "    for f in sorted(Path(path).glob('study*.txt')):\n",
        "        y = np.loadtxt(f, dtype=np.float32, usecols=[0, 1, 2, 3, 7, 8, 9], ndmin=2).T\n",
        "        x = np.arange(y.shape[1]) if x is None else np.array(x)\n",
        "        s = ['P', 'R', 'mAP@.5', 'mAP@.5:.95', 't_inference (ms/img)', 't_NMS (ms/img)', 't_total (ms/img)']\n",
        "        # for i in range(7):\n",
        "        #     ax[i].plot(x, y[i], '.-', linewidth=2, markersize=8)\n",
        "        #     ax[i].set_title(s[i])\n",
        "\n",
        "        j = y[3].argmax() + 1\n",
        "        ax2.plot(y[6, 1:j], y[3, 1:j] * 1E2, '.-', linewidth=2, markersize=8,\n",
        "                 label=f.stem.replace('study_coco_', '').replace('yolo', 'YOLO'))\n",
        "\n",
        "    ax2.plot(1E3 / np.array([209, 140, 97, 58, 35, 18]), [34.6, 40.5, 43.0, 47.5, 49.7, 51.5],\n",
        "             'k.-', linewidth=2, markersize=8, alpha=.25, label='EfficientDet')\n",
        "\n",
        "    ax2.grid(alpha=0.2)\n",
        "    ax2.set_yticks(np.arange(20, 60, 5))\n",
        "    ax2.set_xlim(0, 57)\n",
        "    ax2.set_ylim(30, 55)\n",
        "    ax2.set_xlabel('GPU Speed (ms/img)')\n",
        "    ax2.set_ylabel('COCO AP val')\n",
        "    ax2.legend(loc='lower right')\n",
        "    plt.savefig(str(Path(path).name) + '.png', dpi=300)\n",
        "\n",
        "\n",
        "def plot_labels(labels, names=(), save_dir=Path(''), loggers=None):\n",
        "    # plot dataset labels\n",
        "    print('Plotting labels... ')\n",
        "    c, b = labels[:, 0], labels[:, 1:].transpose()  # classes, boxes\n",
        "    nc = int(c.max() + 1)  # number of classes\n",
        "    colors = color_list()\n",
        "    x = pd.DataFrame(b.transpose(), columns=['x', 'y', 'width', 'height'])\n",
        "\n",
        "    # seaborn correlogram\n",
        "    sns.pairplot(x, corner=True, diag_kind='auto', kind='hist', diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))\n",
        "    plt.savefig(save_dir / 'labels_correlogram.jpg', dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # matplotlib labels\n",
        "    matplotlib.use('svg')  # faster\n",
        "    ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)[1].ravel()\n",
        "    ax[0].hist(c, bins=np.linspace(0, nc, nc + 1) - 0.5, rwidth=0.8)\n",
        "    ax[0].set_ylabel('instances')\n",
        "    if 0 < len(names) < 30:\n",
        "        ax[0].set_xticks(range(len(names)))\n",
        "        ax[0].set_xticklabels(names, rotation=90, fontsize=10)\n",
        "    else:\n",
        "        ax[0].set_xlabel('classes')\n",
        "    sns.histplot(x, x='x', y='y', ax=ax[2], bins=50, pmax=0.9)\n",
        "    sns.histplot(x, x='width', y='height', ax=ax[3], bins=50, pmax=0.9)\n",
        "\n",
        "    # rectangles\n",
        "    labels[:, 1:3] = 0.5  # center\n",
        "    labels[:, 1:] = xywh2xyxy(labels[:, 1:]) * 2000\n",
        "    img = Image.fromarray(np.ones((2000, 2000, 3), dtype=np.uint8) * 255)\n",
        "    for cls, *box in labels[:1000]:\n",
        "        ImageDraw.Draw(img).rectangle(box, width=1, outline=colors[int(cls) % 10])  # plot\n",
        "    ax[1].imshow(img)\n",
        "    ax[1].axis('off')\n",
        "\n",
        "    for a in [0, 1, 2, 3]:\n",
        "        for s in ['top', 'right', 'left', 'bottom']:\n",
        "            ax[a].spines[s].set_visible(False)\n",
        "\n",
        "    plt.savefig(save_dir / 'labels.jpg', dpi=200)\n",
        "    matplotlib.use('Agg')\n",
        "    plt.close()\n",
        "\n",
        "    # loggers\n",
        "    for k, v in loggers.items() or {}:\n",
        "        if k == 'wandb' and v:\n",
        "            v.log({\"Labels\": [v.Image(str(x), caption=x.name) for x in save_dir.glob('*labels*.jpg')]}, commit=False)\n",
        "\n",
        "\n",
        "def plot_evolution(yaml_file='data/hyp.finetune.yaml'):  # from utils.plots import *; plot_evolution()\n",
        "    # Plot hyperparameter evolution results in evolve.txt\n",
        "    with open(yaml_file) as f:\n",
        "        hyp = yaml.load(f, Loader=yaml.SafeLoader)\n",
        "    x = np.loadtxt('evolve.txt', ndmin=2)\n",
        "    f = fitness(x)\n",
        "    # weights = (f - f.min()) ** 2  # for weighted results\n",
        "    plt.figure(figsize=(10, 12), tight_layout=True)\n",
        "    matplotlib.rc('font', **{'size': 8})\n",
        "    for i, (k, v) in enumerate(hyp.items()):\n",
        "        y = x[:, i + 7]\n",
        "        # mu = (y * weights).sum() / weights.sum()  # best weighted result\n",
        "        mu = y[f.argmax()]  # best single result\n",
        "        plt.subplot(6, 5, i + 1)\n",
        "        plt.scatter(y, f, c=hist2d(y, f, 20), cmap='viridis', alpha=.8, edgecolors='none')\n",
        "        plt.plot(mu, f.max(), 'k+', markersize=15)\n",
        "        plt.title('%s = %.3g' % (k, mu), fontdict={'size': 9})  # limit to 40 characters\n",
        "        if i % 5 != 0:\n",
        "            plt.yticks([])\n",
        "        print('%15s: %.3g' % (k, mu))\n",
        "    plt.savefig('evolve.png', dpi=200)\n",
        "    print('\\nPlot saved as evolve.png')\n",
        "\n",
        "\n",
        "def profile_idetection(start=0, stop=0, labels=(), save_dir=''):\n",
        "    # Plot iDetection '*.txt' per-image logs. from utils.plots import *; profile_idetection()\n",
        "    ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)[1].ravel()\n",
        "    s = ['Images', 'Free Storage (GB)', 'RAM Usage (GB)', 'Battery', 'dt_raw (ms)', 'dt_smooth (ms)', 'real-world FPS']\n",
        "    files = list(Path(save_dir).glob('frames*.txt'))\n",
        "    for fi, f in enumerate(files):\n",
        "        try:\n",
        "            results = np.loadtxt(f, ndmin=2).T[:, 90:-30]  # clip first and last rows\n",
        "            n = results.shape[1]  # number of rows\n",
        "            x = np.arange(start, min(stop, n) if stop else n)\n",
        "            results = results[:, x]\n",
        "            t = (results[0] - results[0].min())  # set t0=0s\n",
        "            results[0] = x\n",
        "            for i, a in enumerate(ax):\n",
        "                if i < len(results):\n",
        "                    label = labels[fi] if len(labels) else f.stem.replace('frames_', '')\n",
        "                    a.plot(t, results[i], marker='.', label=label, linewidth=1, markersize=5)\n",
        "                    a.set_title(s[i])\n",
        "                    a.set_xlabel('time (s)')\n",
        "                    # if fi == len(files) - 1:\n",
        "                    #     a.set_ylim(bottom=0)\n",
        "                    for side in ['top', 'right']:\n",
        "                        a.spines[side].set_visible(False)\n",
        "                else:\n",
        "                    a.remove()\n",
        "        except Exception as e:\n",
        "            print('Warning: Plotting error for %s; %s' % (f, e))\n",
        "\n",
        "    ax[1].legend()\n",
        "    plt.savefig(Path(save_dir) / 'idetection_profile.png', dpi=200)\n",
        "\n",
        "\n",
        "def plot_results_overlay(start=0, stop=0):  # from utils.plots import *; plot_results_overlay()\n",
        "    # Plot training 'results*.txt', overlaying train and val losses\n",
        "    s = ['train', 'train', 'train', 'Precision', 'mAP@0.5', 'val', 'val', 'val', 'Recall', 'mAP@0.5:0.95']  # legends\n",
        "    t = ['Box', 'Objectness', 'Classification', 'P-R', 'mAP-F1']  # titles\n",
        "    for f in sorted(glob.glob('results*.txt') + glob.glob('../../Downloads/results*.txt')):\n",
        "        results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T\n",
        "        n = results.shape[1]  # number of rows\n",
        "        x = range(start, min(stop, n) if stop else n)\n",
        "        fig, ax = plt.subplots(1, 5, figsize=(14, 3.5), tight_layout=True)\n",
        "        ax = ax.ravel()\n",
        "        for i in range(5):\n",
        "            for j in [i, i + 5]:\n",
        "                y = results[j, x]\n",
        "                ax[i].plot(x, y, marker='.', label=s[j])\n",
        "                # y_smooth = butter_lowpass_filtfilt(y)\n",
        "                # ax[i].plot(x, np.gradient(y_smooth), marker='.', label=s[j])\n",
        "\n",
        "            ax[i].set_title(t[i])\n",
        "            ax[i].legend()\n",
        "            ax[i].set_ylabel(f) if i == 0 else None  # add filename\n",
        "        fig.savefig(f.replace('.txt', '.png'), dpi=200)\n",
        "\n",
        "\n",
        "def plot_results(start=0, stop=0, bucket='', id=(), labels=(), save_dir=''):\n",
        "    # Plot training 'results*.txt'. from utils.plots import *; plot_results(save_dir='runs/train/exp')\n",
        "    fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)\n",
        "    ax = ax.ravel()\n",
        "    s = ['Box', 'Objectness', 'Classification', 'Precision', 'Recall',\n",
        "         'val Box', 'val Objectness', 'val Classification', 'mAP@0.5', 'mAP@0.5:0.95']\n",
        "    if bucket:\n",
        "        # files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]\n",
        "        files = ['results%g.txt' % x for x in id]\n",
        "        c = ('gsutil cp ' + '%s ' * len(files) + '.') % tuple('gs://%s/results%g.txt' % (bucket, x) for x in id)\n",
        "        os.system(c)\n",
        "    else:\n",
        "        files = list(Path(save_dir).glob('results*.txt'))\n",
        "    assert len(files), 'No results.txt files found in %s, nothing to plot.' % os.path.abspath(save_dir)\n",
        "    for fi, f in enumerate(files):\n",
        "        try:\n",
        "            results = np.loadtxt(f, usecols=[2, 3, 4, 8, 9, 12, 13, 14, 10, 11], ndmin=2).T\n",
        "            n = results.shape[1]  # number of rows\n",
        "            x = range(start, min(stop, n) if stop else n)\n",
        "            for i in range(10):\n",
        "                y = results[i, x]\n",
        "                if i in [0, 1, 2, 5, 6, 7]:\n",
        "                    y[y == 0] = np.nan  # don't show zero loss values\n",
        "                    # y /= y[0]  # normalize\n",
        "                label = labels[fi] if len(labels) else f.stem\n",
        "                ax[i].plot(x, y, marker='.', label=label, linewidth=2, markersize=8)\n",
        "                ax[i].set_title(s[i])\n",
        "                # if i in [5, 6, 7]:  # share train and val loss y axes\n",
        "                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])\n",
        "        except Exception as e:\n",
        "            print('Warning: Plotting error for %s; %s' % (f, e))\n",
        "\n",
        "    ax[1].legend()\n",
        "    fig.savefig(Path(save_dir) / 'results.png', dpi=200)\n",
        "    \n",
        "    \n",
        "def output_to_keypoint(output):\n",
        "    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]\n",
        "    targets = []\n",
        "    for i, o in enumerate(output):\n",
        "        kpts = o[:,6:]\n",
        "        o = o[:,:6]\n",
        "        for index, (*box, conf, cls) in enumerate(o.detach().cpu().numpy()):\n",
        "            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf, *list(kpts.detach().cpu().numpy()[index])])\n",
        "    return np.array(targets)\n",
        "\n",
        "\n",
        "def plot_skeleton_kpts(im, imorg, input_size, kpts, steps, orig_shape=None):\n",
        "    org_h, org_w = imorg.shape[:2]\n",
        "    #Plot the skeleton and keypointsfor coco datatset\n",
        "    palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],\n",
        "                        [230, 230, 0], [255, 153, 255], [153, 204, 255],\n",
        "                        [255, 102, 255], [255, 51, 255], [102, 178, 255],\n",
        "                        [51, 153, 255], [255, 153, 153], [255, 102, 102],\n",
        "                        [255, 51, 51], [153, 255, 153], [102, 255, 102],\n",
        "                        [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0],\n",
        "                        [255, 255, 255]])\n",
        "\n",
        "    skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12],\n",
        "                [7, 13], [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3],\n",
        "                [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]\n",
        "\n",
        "    pose_limb_color = palette[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]\n",
        "    pose_kpt_color = palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]\n",
        "    radius = 5\n",
        "    num_kpts = len(kpts) // steps\n",
        "\n",
        "    for kid in range(num_kpts):\n",
        "        r, g, b = pose_kpt_color[kid]\n",
        "        x_coord, y_coord = kpts[steps * kid], kpts[steps * kid + 1]\n",
        "        if not (x_coord % 640 == 0 or y_coord % 640 == 0):\n",
        "            if steps == 3:\n",
        "                conf = kpts[steps * kid + 2]\n",
        "                if conf < 0.5:\n",
        "                    continue\n",
        "            cv2.circle(im, (int(x_coord), int(y_coord)), radius, (int(r), int(g), int(b)), -1)\n",
        "            # print('X : ', x_coord, 'Y: ', y_coord)\n",
        "            # Modified Image after resize.\n",
        "            xm = int((org_w/input_size)*x_coord)\n",
        "            ym = int((org_h/input_size)*y_coord)\n",
        "            cv2.circle(imorg, (xm, ym), radius, (int(r), int(g), int(b)), -1)\n",
        "\n",
        "    for sk_id, sk in enumerate(skeleton):\n",
        "        r, g, b = pose_limb_color[sk_id]\n",
        "        pos1 = (int(kpts[(sk[0]-1)*steps]), int(kpts[(sk[0]-1)*steps+1]))\n",
        "        pos2 = (int(kpts[(sk[1]-1)*steps]), int(kpts[(sk[1]-1)*steps+1]))\n",
        "        if steps == 3:\n",
        "            conf1 = kpts[(sk[0]-1)*steps+2]\n",
        "            conf2 = kpts[(sk[1]-1)*steps+2]\n",
        "            if conf1<0.5 or conf2<0.5:\n",
        "                continue\n",
        "        if pos1[0]%640 == 0 or pos1[1]%640==0 or pos1[0]<0 or pos1[1]<0:\n",
        "            continue\n",
        "        if pos2[0] % 640 == 0 or pos2[1] % 640 == 0 or pos2[0]<0 or pos2[1]<0:\n",
        "            continue\n",
        "        cv2.line(im, pos1, pos2, (int(r), int(g), int(b)), thickness=2, lineType=cv2.LINE_AA)\n",
        "\n",
        "        ## Modification\n",
        "        x11, y11 = pos1[0], pos1[1]\n",
        "        x22, y22 = pos2[0], pos2[1]\n",
        "\n",
        "        xf = org_w/input_size\n",
        "        yf = org_h/input_size\n",
        "\n",
        "        x11 = int(xf*x11)\n",
        "        x22 = int(xf*x22)\n",
        "        y11 = int(yf*y11)\n",
        "        y22 = int(yf*y22)\n",
        "\n",
        "        cv2.line(imorg, (x11, y11), (x22, y22), (int(r), int(g), int(b)), thickness=1, lineType=cv2.LINE_AA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KgJ6CmGCX_9W"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general  import non_max_suppression_kpt\n",
        "from utils.plots    import output_to_keypoint, plot_skeleton_kpts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hJ4j6wDofLFe"
      },
      "outputs": [],
      "source": [
        "def pose_video(frame):\n",
        "    mapped_img = frame.copy()\n",
        "    # Letterbox resizing.\n",
        "    img = letterbox(frame, input_size, stride=64, auto=True)[0]\n",
        "    img_ = img.copy()\n",
        "    # Convert the array to 4D.\n",
        "    img = transforms.ToTensor()(img)\n",
        "    # Convert the array to Tensor.\n",
        "    img = torch.tensor(np.array([img.numpy()]))\n",
        "    # Load the image into the computation device.\n",
        "    img = img.to(device)\n",
        "    \n",
        "    # Gradients are stored during training, not required while inference.\n",
        "    with torch.no_grad():\n",
        "        t1 = time.time()\n",
        "        output, _ = model(img)\n",
        "        t2 = time.time()\n",
        "        fps = 1/(t2 - t1)\n",
        "        output = non_max_suppression_kpt(output, \n",
        "                                         0.25,    # Conf. Threshold.\n",
        "                                         0.65,    # IoU Threshold.\n",
        "                                         nc=1,   # Number of classes.\n",
        "                                         nkpt=17, # Number of keypoints.\n",
        "                                         kpt_label=True)\n",
        "        \n",
        "        output = output_to_keypoint(output)\n",
        "\n",
        "    # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n",
        "    nimg = img[0].permute(1, 2, 0) * 255\n",
        "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    for idx in range(output.shape[0]):\n",
        "        plot_skeleton_kpts(nimg, mapped_img, input_size, output[idx, 7:].T, 3)\n",
        "        xmin, ymin = (output[idx,2] - output[idx,4]/2), (output[idx,3] - output[idx,5]/2)\n",
        "        xmax, ymax = (output[idx,2] + output[idx,4]/2), (output[idx,3] + output[idx,5]/2)\n",
        "        dx = int(xmax) - int(xmin)\n",
        "        dy = int(ymax) - int(ymin)\n",
        "\n",
        "    # in case there's not even 1 prediction at all\n",
        "    if output.shape[0] == 0:\n",
        "        dx, dy, xmin, ymin, xmax, ymax = 0,0,0,0,0,0\n",
        "        \n",
        "    return nimg, fps, dx, dy, xmin, ymin, xmax, ymax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF_e5_V4gB0U",
        "outputId": "38ac7200-3819-476d-e4e9-1b1c95cf27b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Device :  cpu\n"
          ]
        }
      ],
      "source": [
        "# #------------------------------------------------------------------------------#\n",
        "# # Change forward pass input size.\n",
        "input_size = 256\n",
        "\n",
        "#---------------------------INITIALIZATIONS------------------------------------#\n",
        "\n",
        "# Select the device based on hardware configs.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('Selected Device : ', device)\n",
        "\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "# Load keypoint detection model.\n",
        "weights = torch.load('yolov7-w6-pose.pt', map_location=device)\n",
        "model = weights['model']\n",
        "# Load the model in evaluation mode.\n",
        "_ = model.float().eval()\n",
        "# Load the model to computation device [cpu/gpu/tpu]\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nxHj57MMgEVc",
        "outputId": "881de062-c414-439b-b3e4-e77d8056611c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unable to read frame. Exiting ..\n"
          ]
        }
      ],
      "source": [
        "vid_path = 'Media/default.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(vid_path)\n",
        "\n",
        "#check if videocapture not opened\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Please check path again')\n",
        "    \n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "ret, frame = cap.read()\n",
        "h, w, _ = frame.shape\n",
        "file_name = 'video_key.mp4'\n",
        "out = cv2.VideoWriter('Media/' + file_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (input_size, input_size))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        print('Unable to read frame. Exiting ..')\n",
        "        break\n",
        "\n",
        "    img, fps, dx1, dy1, xmin, ymin, xmax, ymax = pose_video(frame)\n",
        "    \n",
        "    # Fall detection\n",
        "    if (dy1 - dx1)< 0:\n",
        "        # draw red bounding box\n",
        "        cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),color=(255, 0, 0),\n",
        "                thickness=5,lineType=cv2.LINE_AA)\n",
        "        # draw red small upper box\n",
        "        cv2.putText(img, 'FALL DETECTED!!!', (int(xmin), int(ymin)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (255, 0, 0), 2)\n",
        "\n",
        "    # cv2.putText(img, 'FPS : {:.2f}'.format(fps_), (200, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
        "    # cv2.putText(img, 'YOLOv7', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # img[...,::-1] is to convert BGR to RGB\n",
        "    cv2.imshow('Output', img[...,::-1])\n",
        "    out.write(img[...,::-1])\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\kyunomi\\Desktop\\lauretta\\yolov7_pose\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing Dockerfile\n"
          ]
        }
      ],
      "source": [
        "%%writefile Dockerfile\n",
        "\n",
        "FROM python:3.8 \n",
        "\n",
        "# Copy all the files needed for the app to work\n",
        "COPY inference.py .\n",
        "COPY requirements.txt .\n",
        "COPY yolov7/ ./yolov7/\n",
        "\n",
        "# Install all the necessary libraries\n",
        "RUN apt-get update && apt-get install -y git ffmpeg libsm6 libxext6 libgl1-mesa-glx libgl1 libglib2.0-0 python3-opencv\n",
        "RUN pip install -r requirements.txt\n",
        "RUN pip install git+https://github.com/facebookresearch/detectron2.git\n",
        "RUN pip install opencv-python\n",
        "RUN pip install opencv-contrib-python-headless\n",
        "\n",
        "# Run the API!\n",
        "CMD python inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "pandas\n",
        "flask\n",
        "torch==1.10.1\n",
        "torchvision==0.11.2\n",
        "torchaudio==0.10.1\n",
        "lxml==4.9.1\n",
        "av\n",
        "\n",
        "# YOLOv5 requirements\n",
        "# Usage: pip install -r requirements.txt\n",
        "\n",
        "# Base ----------------------------------------\n",
        "matplotlib>=3.2.2\n",
        "numpy>=1.18.5\n",
        "opencv-python>=4.1.1\n",
        "Pillow>=7.1.2\n",
        "PyYAML>=5.3.1\n",
        "requests>=2.23.0\n",
        "scipy>=1.4.1\n",
        "tqdm>=4.64.0\n",
        "protobuf<=3.20.1  # https://github.com/ultralytics/yolov5/issues/8012\n",
        "\n",
        "# Logging -------------------------------------\n",
        "tensorboard>=2.4.1\n",
        "# wandb\n",
        "# clearml\n",
        "\n",
        "# Plotting ------------------------------------\n",
        "seaborn>=0.11.0\n",
        "\n",
        "# Export --------------------------------------\n",
        "# coremltools>=5.2  # CoreML export\n",
        "# onnx>=1.9.0  # ONNX export\n",
        "# onnx-simplifier>=0.4.1  # ONNX simplifier\n",
        "# nvidia-pyindex  # TensorRT export\n",
        "# nvidia-tensorrt  # TensorRT export\n",
        "# scikit-learn==0.19.2  # CoreML quantization\n",
        "# tensorflow>=2.4.1  # TFLite export (or tensorflow-cpu, tensorflow-aarch64)\n",
        "# tensorflowjs>=3.9.0  # TF.js export\n",
        "# openvino-dev  # OpenVINO export\n",
        "\n",
        "# Extras --------------------------------------\n",
        "ipython  # interactive notebook\n",
        "psutil  # system utilization\n",
        "thop>=0.1.1  # FLOPs computation\n",
        "# albumentations>=1.0.3\n",
        "# pycocotools>=2.0  # COCO mAP\n",
        "# roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing inference.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile inference.py\n",
        "import time\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general  import non_max_suppression_kpt\n",
        "from utils.plots    import output_to_keypoint, plot_skeleton_kpts\n",
        "\n",
        "def pose_video(frame):\n",
        "    mapped_img = frame.copy()\n",
        "    # Letterbox resizing.\n",
        "    img = letterbox(frame, input_size, stride=64, auto=True)[0]\n",
        "    img_ = img.copy()\n",
        "    # Convert the array to 4D.\n",
        "    img = transforms.ToTensor()(img)\n",
        "    # Convert the array to Tensor.\n",
        "    img = torch.tensor(np.array([img.numpy()]))\n",
        "    # Load the image into the computation device.\n",
        "    img = img.to(device)\n",
        "    \n",
        "    # Gradients are stored during training, not required while inference.\n",
        "    with torch.no_grad():\n",
        "        t1 = time.time()\n",
        "        output, _ = model(img)\n",
        "        t2 = time.time()\n",
        "        fps = 1/(t2 - t1)\n",
        "        output = non_max_suppression_kpt(output, \n",
        "                                         0.25,    # Conf. Threshold.\n",
        "                                         0.65,    # IoU Threshold.\n",
        "                                         nc=1,   # Number of classes.\n",
        "                                         nkpt=17, # Number of keypoints.\n",
        "                                         kpt_label=True)\n",
        "        \n",
        "        output = output_to_keypoint(output)\n",
        "\n",
        "    # Change format [b, c, h, w] to [h, w, c] for displaying the image.\n",
        "    nimg = img[0].permute(1, 2, 0) * 255\n",
        "    nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "    nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    for idx in range(output.shape[0]):\n",
        "        plot_skeleton_kpts(nimg, mapped_img, input_size, output[idx, 7:].T, 3)\n",
        "        xmin, ymin = (output[idx,2] - output[idx,4]/2), (output[idx,3] - output[idx,5]/2)\n",
        "        xmax, ymax = (output[idx,2] + output[idx,4]/2), (output[idx,3] + output[idx,5]/2)\n",
        "        dx = int(xmax) - int(xmin)\n",
        "        dy = int(ymax) - int(ymin)\n",
        "\n",
        "    # in case there's not even 1 prediction at all\n",
        "    if output.shape[0] == 0:\n",
        "        dx, dy, xmin, ymin, xmax, ymax = 0,0,0,0,0,0\n",
        "        \n",
        "    return nimg, fps, dx, dy, xmin, ymin, xmax, ymax\n",
        "\n",
        "\n",
        "# #------------------------------------------------------------------------------#\n",
        "# # Change forward pass input size.\n",
        "input_size = 256\n",
        "\n",
        "#---------------------------INITIALIZATIONS------------------------------------#\n",
        "\n",
        "# Select the device based on hardware configs.\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('Selected Device : ', device)\n",
        "\n",
        "# device = torch.device(\"cpu\")\n",
        "\n",
        "# Load keypoint detection model.\n",
        "weights = torch.load('yolov7-w6-pose.pt', map_location=device)\n",
        "model = weights['model']\n",
        "# Load the model in evaluation mode.\n",
        "_ = model.float().eval()\n",
        "# Load the model to computation device [cpu/gpu/tpu]\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "vid_path = 'Media/default.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(vid_path)\n",
        "\n",
        "#check if videocapture not opened\n",
        "if (cap.isOpened() == False):\n",
        "    print('Error while trying to read video. Please check path again')\n",
        "    \n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "ret, frame = cap.read()\n",
        "h, w, _ = frame.shape\n",
        "file_name = 'video_key.mp4'\n",
        "out = cv2.VideoWriter('Media/' + file_name, cv2.VideoWriter_fourcc(*'mp4v'), fps, (input_size, input_size))\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    if not ret:\n",
        "        print('Unable to read frame. Exiting ..')\n",
        "        break\n",
        "\n",
        "    img, fps, dx1, dy1, xmin, ymin, xmax, ymax = pose_video(frame)\n",
        "    \n",
        "    # Fall detection\n",
        "    if (dy1 - dx1)< 0:\n",
        "        # draw red bounding box\n",
        "        cv2.rectangle(img,(int(xmin), int(ymin)),(int(xmax), int(ymax)),color=(255, 0, 0),\n",
        "                thickness=5,lineType=cv2.LINE_AA)\n",
        "        # draw red small upper box\n",
        "        cv2.putText(img, 'FALL DETECTED!!!', (int(xmin), int(ymin)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.25, (255, 0, 0), 2)\n",
        "\n",
        "    # cv2.putText(img, 'FPS : {:.2f}'.format(fps_), (200, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
        "    # cv2.putText(img, 'YOLOv7', (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # img[...,::-1] is to convert BGR to RGB\n",
        "    cv2.imshow('Output', img[...,::-1])\n",
        "    out.write(img[...,::-1])\n",
        "    key = cv2.waitKey(1)\n",
        "    if key == ord('q'):\n",
        "      break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('lauretta')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "37c2c77dc877df0cc7f229684be4664bfbf94760f81bab460f27332317ae4aba"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
