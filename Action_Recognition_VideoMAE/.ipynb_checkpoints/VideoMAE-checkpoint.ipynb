{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b9b84cf3f1d41d694efb4a0774f535d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VideoModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VideoModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VideoView",
            "autoplay": true,
            "controls": true,
            "format": "mp4",
            "height": "",
            "layout": "IPY_MODEL_4f94ef20caf74697b8f1bf59055d4fc7",
            "loop": true,
            "width": "240"
          }
        },
        "4f94ef20caf74697b8f1bf59055d4fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuXX2RCRMn8k",
        "outputId": "3b07cf06-93ef-429d-b005-27b38e684211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q decord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmdFyCw5NGPZ",
        "outputId": "2a64504f-a9da-45fe-e742-19d54f36d8b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 13.6 MB 10.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-dl ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh9AVKePUyAC",
        "outputId": "2415fbab-3d23-4dbf-e0ed-62125879ee1b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 13.7 MB/s \n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6084 sha256=c80d8adcb45f5ed0b517333ad28f4ad1c1ac7b03fc54e214e8610af7fd9c4d0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/33/46/5ab7eca55b9490dddbf3441c68a29535996270ef1ce8b9b6d7\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: youtube-dl, ffmpeg\n",
            "Successfully installed ffmpeg-1.4 youtube-dl-2021.12.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkIG7j4LNYCQ",
        "outputId": "49bcea0b-e5e0-4a2a-aaf3-bcfc4e37d42b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VideoMAEFeatureExtractor, VideoMAEForVideoClassification\n",
        "import torch\n",
        "\n",
        "feature_extractor = VideoMAEFeatureExtractor.from_pretrained(\"MCG-NJU/videomae-base-finetuned-kinetics\")\n",
        "model = VideoMAEForVideoClassification.from_pretrained(\"a\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3Mz7NqqN69-",
        "outputId": "f103a4a6-e25b-49d3-b868-6cab086bf952"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VideoMAEForVideoClassification(\n",
              "  (videomae): VideoMAEModel(\n",
              "    (embeddings): VideoMAEEmbeddings(\n",
              "      (patch_embeddings): VideoMAEPatchEmbeddings(\n",
              "        (projection): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
              "      )\n",
              "    )\n",
              "    (encoder): VideoMAEEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (6): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (7): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (8): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (9): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (10): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (11): VideoMAELayer(\n",
              "          (attention): VideoMAEAttention(\n",
              "            (attention): VideoMAESelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): VideoMAESelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): VideoMAEIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): VideoMAEOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  (classifier): Linear(in_features=768, out_features=400, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import youtube_dl\n",
        "\n",
        "url = 'https://www.youtube.com/shorts/CQZdidYMMPw'\n",
        "# we use replace as youtube_dl does not currently work with youtube shorts url\n",
        "url = url.replace('shorts/','watch?v=')\n",
        "ydl_opts = {\n",
        "        'format':'mp4[width<=?360][height<=?360]',\n",
        "        'noplaylist': True,\n",
        "        'outtmpl': '/content/drive/MyDrive/lauretta/test.mp4',\n",
        "    }\n",
        "ydl = youtube_dl.YoutubeDL(ydl_opts)\n",
        "try:\n",
        "  os.remove('/content/drive/MyDrive/lauretta/test.mp4')\n",
        "except:\n",
        "  pass\n",
        "finally:\n",
        "  ydl.download([url])\n",
        "# # set video url, extract video information\n",
        "# info_dict = ydl.extract_info(url, download=False)\n",
        "\n",
        "# # get video formats available\n",
        "# formats = info_dict.get('formats',None)\n",
        "\n",
        "# for format in formats:\n",
        "\n",
        "#   # I want the lowest resolution, so I set resolution as 144p\n",
        "#   if format['format_note'] == '240p' and format['ext'] == 'mp4':\n",
        "#     try:\n",
        "#       os.remove('/content/drive/MyDrive/lauretta/test.mp4')\n",
        "#     except:\n",
        "#       pass\n",
        "#     finally:\n",
        "#       ydl.download([url])\n",
        "#       break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIMBtfGjPaM",
        "outputId": "c1c0739b-1f46-41b9-ed88-2eaf20404677"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] CQZdidYMMPw: Downloading webpage\n",
            "[youtube] Downloading just video CQZdidYMMPw because of --no-playlist\n",
            "[download] Destination: /content/drive/MyDrive/lauretta/test.mp4\n",
            "[download] 100% of 375.46KiB in 00:05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url = 'https://www.youtube.com/shorts/PB1H8YSZfIk'\n",
        "# # we use replace as youtube_dl does not currently work with youtube shorts url\n",
        "# url = url.replace('shorts/','watch?v=')\n",
        "# ydl_opts = {\n",
        "#         'noplaylist': True,\n",
        "#         'outtmpl': '/content/drive/MyDrive/lauretta/test.mp4',\n",
        "#     }\n",
        "# ydl = youtube_dl.YoutubeDL(ydl_opts)\n",
        "\n",
        "\n",
        "# # set video url, extract video information\n",
        "# info_dict = ydl.extract_info(url, download=False)\n",
        "\n",
        "# # get video formats available\n",
        "# formats = info_dict.get('formats',None)\n",
        "# formats"
      ],
      "metadata": {
        "id": "KsMh3c_IxX7G"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ipywidgets import Video\n",
        "\n",
        "# video_path = \"/content/drive/MyDrive/lauretta/pizza.mp4\" \n",
        "# video_path = \"/content/drive/MyDrive/lauretta/pull up.mp4\" \n",
        "# video_path = \"/content/drive/MyDrive/lauretta/baby.mp4\" \n",
        "video_path = \"/content/drive/MyDrive/lauretta/test.mp4\" \n",
        "Video.from_file(video_path, width=240)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453,
          "referenced_widgets": [
            "0b9b84cf3f1d41d694efb4a0774f535d",
            "4f94ef20caf74697b8f1bf59055d4fc7"
          ]
        },
        "id": "i9UAXljqN352",
        "outputId": "a40979ea-3567-4987-d60d-e445de874dfa"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00\\x18ftypmp42\\x00\\x00\\x00\\x00isommp42\\x00\\x00\\x17Dmoov\\x00\\x00\\x00lmvhd\\x00\\x00\\x00\\x…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b9b84cf3f1d41d694efb4a0774f535d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from decord import VideoReader, cpu # decord is a faster alternative of opencv\n",
        "import numpy as np\n",
        "\n",
        "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
        "vr = VideoReader(video_path, num_threads=1, ctx=cpu(0)) \n",
        "\n",
        "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
        "  # As the model only allow 16 frames as input\n",
        "  # we will sample 16 frames from the video\n",
        "\n",
        "  # get the total number of frames that our sample would span across\n",
        "  converted_len = int(clip_len * frame_sample_rate)\n",
        "  # get a randomised max frame of the video. This would be the last frame out of the 16 frame\n",
        "  end_idx = np.random.randint(converted_len, seg_len)\n",
        "  # get the first frame sample\n",
        "  str_idx = end_idx - converted_len\n",
        "  # evenly space out the frame between the start and end frame according to the frame sample rate\n",
        "  index = np.linspace(str_idx, end_idx, num=clip_len)\n",
        "  # ensure frames' index is within range and convert to numpy array\n",
        "  index = np.clip(index, str_idx, end_idx - 1).astype(np.int64)\n",
        "\n",
        "  # # we change the linspace to be spread from 20 to 80 percentile to capture more info across the video\n",
        "  # index = np.linspace(seg_len*0.2, seg_len*0.8, num=clip_len)\n",
        "  # index = np.clip(index, seg_len*0.2, seg_len*0.8 - 1).astype(np.int64)\n",
        "  return index\n",
        "\n",
        "# we run vr.seek(0) to start the read\n",
        "vr.seek(0)\n",
        "# get the np array of frames\n",
        "index = sample_frame_indices(clip_len=16, frame_sample_rate=5, seg_len=len(vr))\n",
        "# get the frame rgb values as numpy (16 frames, height, width, rgb)\n",
        "buffer = vr.get_batch(index).asnumpy()\n",
        "buffer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9NpiJ_KOPmX",
        "outputId": "a29f1ec9-72ca-4ed0-fe5e-7359f80d8a54"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 360, 202, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a list of NumPy arrays\n",
        "video = [buffer[i] for i in range(buffer.shape[0])]\n",
        "\n",
        "# extract features based on previous pipeline\n",
        "encoding = feature_extractor(video, return_tensors=\"pt\")\n",
        "print(encoding.pixel_values.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6WlmR3KPP_x",
        "outputId": "656631f5-3aac-4658-de6a-77c76a78165f"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "uvqwsth3PolI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pixel_values = encoding.pixel_values.to(device)\n",
        "\n",
        "# forward pass\n",
        "with torch.no_grad():\n",
        "  outputs = model(pixel_values)\n",
        "  logits = outputs.logits"
      ],
      "metadata": {
        "id": "8auy_9LnPnmj"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiMiCVpFP49i",
        "outputId": "497c09b3-fecf-4dc5-a473-0421a2d233dc"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: riding or walking with horse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zJwyAKw-QV1V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}